nohup: ignoring input
W1028 15:23:12.713439 63518 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 12.2, Runtime API Version: 12.0
W1028 15:23:12.714071 63518 gpu_resources.cc:164] device: 0, cuDNN Version: 9.5.
(1200, 64, 64, 20)
Dataloading is over.
Namespace(lr=0.001, epochs=500, weight_decay=1e-05, model='Transolver_Structured_Mesh_2D', n_hidden=256, n_layers=8, n_heads=8, batch_size=2, gpu=0, max_grad_norm=None, downsample=1, mlp_ratio=1, dropout=0.0, unified_pos=1, ref=8, slice_num=32, eval=0, save_name='ns_Transolver', data_path='data/fno')
Model(
  (preprocess): MLP(
    (linear_pre): Sequential(
      (0): Linear(in_features=74, out_features=512, dtype=None)
      (1): GELU(approximate=False)
    )
    (linear_post): Linear(in_features=512, out_features=256, dtype=None)
    (linears): LayerList()
  )
  (blocks): LayerList(
    (0): Transolver_block(
      (ln_1): LayerNorm(normalized_shape=[256], epsilon=1e-05)
      (Attn): Physics_Attention_Structured_Mesh_2D(
        (softmax): Softmax(axis=-1)
        (dropout): Dropout(p=0.0, axis=None, mode=upscale_in_train)
        (in_project_x): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (in_project_fx): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (in_project_slice): Linear(in_features=32, out_features=32, dtype=None)
        (to_q): Linear(in_features=32, out_features=32, dtype=None)
        (to_k): Linear(in_features=32, out_features=32, dtype=None)
        (to_v): Linear(in_features=32, out_features=32, dtype=None)
        (to_out): Sequential(
          (0): Linear(in_features=256, out_features=256, dtype=None)
          (1): Dropout(p=0.0, axis=None, mode=upscale_in_train)
        )
      )
      (ln_2): LayerNorm(normalized_shape=[256], epsilon=1e-05)
      (mlp): MLP(
        (linear_pre): Sequential(
          (0): Linear(in_features=256, out_features=256, dtype=None)
          (1): GELU(approximate=False)
        )
        (linear_post): Linear(in_features=256, out_features=256, dtype=None)
        (linears): LayerList()
      )
    )
    (1): Transolver_block(
      (ln_1): LayerNorm(normalized_shape=[256], epsilon=1e-05)
      (Attn): Physics_Attention_Structured_Mesh_2D(
        (softmax): Softmax(axis=-1)
        (dropout): Dropout(p=0.0, axis=None, mode=upscale_in_train)
        (in_project_x): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (in_project_fx): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (in_project_slice): Linear(in_features=32, out_features=32, dtype=None)
        (to_q): Linear(in_features=32, out_features=32, dtype=None)
        (to_k): Linear(in_features=32, out_features=32, dtype=None)
        (to_v): Linear(in_features=32, out_features=32, dtype=None)
        (to_out): Sequential(
          (0): Linear(in_features=256, out_features=256, dtype=None)
          (1): Dropout(p=0.0, axis=None, mode=upscale_in_train)
        )
      )
      (ln_2): LayerNorm(normalized_shape=[256], epsilon=1e-05)
      (mlp): MLP(
        (linear_pre): Sequential(
          (0): Linear(in_features=256, out_features=256, dtype=None)
          (1): GELU(approximate=False)
        )
        (linear_post): Linear(in_features=256, out_features=256, dtype=None)
        (linears): LayerList()
      )
    )
    (2): Transolver_block(
      (ln_1): LayerNorm(normalized_shape=[256], epsilon=1e-05)
      (Attn): Physics_Attention_Structured_Mesh_2D(
        (softmax): Softmax(axis=-1)
        (dropout): Dropout(p=0.0, axis=None, mode=upscale_in_train)
        (in_project_x): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (in_project_fx): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (in_project_slice): Linear(in_features=32, out_features=32, dtype=None)
        (to_q): Linear(in_features=32, out_features=32, dtype=None)
        (to_k): Linear(in_features=32, out_features=32, dtype=None)
        (to_v): Linear(in_features=32, out_features=32, dtype=None)
        (to_out): Sequential(
          (0): Linear(in_features=256, out_features=256, dtype=None)
          (1): Dropout(p=0.0, axis=None, mode=upscale_in_train)
        )
      )
      (ln_2): LayerNorm(normalized_shape=[256], epsilon=1e-05)
      (mlp): MLP(
        (linear_pre): Sequential(
          (0): Linear(in_features=256, out_features=256, dtype=None)
          (1): GELU(approximate=False)
        )
        (linear_post): Linear(in_features=256, out_features=256, dtype=None)
        (linears): LayerList()
      )
    )
    (3): Transolver_block(
      (ln_1): LayerNorm(normalized_shape=[256], epsilon=1e-05)
      (Attn): Physics_Attention_Structured_Mesh_2D(
        (softmax): Softmax(axis=-1)
        (dropout): Dropout(p=0.0, axis=None, mode=upscale_in_train)
        (in_project_x): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (in_project_fx): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (in_project_slice): Linear(in_features=32, out_features=32, dtype=None)
        (to_q): Linear(in_features=32, out_features=32, dtype=None)
        (to_k): Linear(in_features=32, out_features=32, dtype=None)
        (to_v): Linear(in_features=32, out_features=32, dtype=None)
        (to_out): Sequential(
          (0): Linear(in_features=256, out_features=256, dtype=None)
          (1): Dropout(p=0.0, axis=None, mode=upscale_in_train)
        )
      )
      (ln_2): LayerNorm(normalized_shape=[256], epsilon=1e-05)
      (mlp): MLP(
        (linear_pre): Sequential(
          (0): Linear(in_features=256, out_features=256, dtype=None)
          (1): GELU(approximate=False)
        )
        (linear_post): Linear(in_features=256, out_features=256, dtype=None)
        (linears): LayerList()
      )
    )
    (4): Transolver_block(
      (ln_1): LayerNorm(normalized_shape=[256], epsilon=1e-05)
      (Attn): Physics_Attention_Structured_Mesh_2D(
        (softmax): Softmax(axis=-1)
        (dropout): Dropout(p=0.0, axis=None, mode=upscale_in_train)
        (in_project_x): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (in_project_fx): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (in_project_slice): Linear(in_features=32, out_features=32, dtype=None)
        (to_q): Linear(in_features=32, out_features=32, dtype=None)
        (to_k): Linear(in_features=32, out_features=32, dtype=None)
        (to_v): Linear(in_features=32, out_features=32, dtype=None)
        (to_out): Sequential(
          (0): Linear(in_features=256, out_features=256, dtype=None)
          (1): Dropout(p=0.0, axis=None, mode=upscale_in_train)
        )
      )
      (ln_2): LayerNorm(normalized_shape=[256], epsilon=1e-05)
      (mlp): MLP(
        (linear_pre): Sequential(
          (0): Linear(in_features=256, out_features=256, dtype=None)
          (1): GELU(approximate=False)
        )
        (linear_post): Linear(in_features=256, out_features=256, dtype=None)
        (linears): LayerList()
      )
    )
    (5): Transolver_block(
      (ln_1): LayerNorm(normalized_shape=[256], epsilon=1e-05)
      (Attn): Physics_Attention_Structured_Mesh_2D(
        (softmax): Softmax(axis=-1)
        (dropout): Dropout(p=0.0, axis=None, mode=upscale_in_train)
        (in_project_x): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (in_project_fx): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (in_project_slice): Linear(in_features=32, out_features=32, dtype=None)
        (to_q): Linear(in_features=32, out_features=32, dtype=None)
        (to_k): Linear(in_features=32, out_features=32, dtype=None)
        (to_v): Linear(in_features=32, out_features=32, dtype=None)
        (to_out): Sequential(
          (0): Linear(in_features=256, out_features=256, dtype=None)
          (1): Dropout(p=0.0, axis=None, mode=upscale_in_train)
        )
      )
      (ln_2): LayerNorm(normalized_shape=[256], epsilon=1e-05)
      (mlp): MLP(
        (linear_pre): Sequential(
          (0): Linear(in_features=256, out_features=256, dtype=None)
          (1): GELU(approximate=False)
        )
        (linear_post): Linear(in_features=256, out_features=256, dtype=None)
        (linears): LayerList()
      )
    )
    (6): Transolver_block(
      (ln_1): LayerNorm(normalized_shape=[256], epsilon=1e-05)
      (Attn): Physics_Attention_Structured_Mesh_2D(
        (softmax): Softmax(axis=-1)
        (dropout): Dropout(p=0.0, axis=None, mode=upscale_in_train)
        (in_project_x): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (in_project_fx): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (in_project_slice): Linear(in_features=32, out_features=32, dtype=None)
        (to_q): Linear(in_features=32, out_features=32, dtype=None)
        (to_k): Linear(in_features=32, out_features=32, dtype=None)
        (to_v): Linear(in_features=32, out_features=32, dtype=None)
        (to_out): Sequential(
          (0): Linear(in_features=256, out_features=256, dtype=None)
          (1): Dropout(p=0.0, axis=None, mode=upscale_in_train)
        )
      )
      (ln_2): LayerNorm(normalized_shape=[256], epsilon=1e-05)
      (mlp): MLP(
        (linear_pre): Sequential(
          (0): Linear(in_features=256, out_features=256, dtype=None)
          (1): GELU(approximate=False)
        )
        (linear_post): Linear(in_features=256, out_features=256, dtype=None)
        (linears): LayerList()
      )
    )
    (7): Transolver_block(
      (ln_1): LayerNorm(normalized_shape=[256], epsilon=1e-05)
      (Attn): Physics_Attention_Structured_Mesh_2D(
        (softmax): Softmax(axis=-1)
        (dropout): Dropout(p=0.0, axis=None, mode=upscale_in_train)
        (in_project_x): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (in_project_fx): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (in_project_slice): Linear(in_features=32, out_features=32, dtype=None)
        (to_q): Linear(in_features=32, out_features=32, dtype=None)
        (to_k): Linear(in_features=32, out_features=32, dtype=None)
        (to_v): Linear(in_features=32, out_features=32, dtype=None)
        (to_out): Sequential(
          (0): Linear(in_features=256, out_features=256, dtype=None)
          (1): Dropout(p=0.0, axis=None, mode=upscale_in_train)
        )
      )
      (ln_2): LayerNorm(normalized_shape=[256], epsilon=1e-05)
      (mlp): MLP(
        (linear_pre): Sequential(
          (0): Linear(in_features=256, out_features=256, dtype=None)
          (1): GELU(approximate=False)
        )
        (linear_post): Linear(in_features=256, out_features=256, dtype=None)
        (linears): LayerList()
      )
      (ln_3): LayerNorm(normalized_shape=[256], epsilon=1e-05)
      (mlp2): Linear(in_features=256, out_features=1, dtype=None)
    )
  )
)
Total Trainable Params: 11232321
Epoch 0 , train_step_loss:0.37562 , train_full_loss:0.44013 , test_step_loss:0.68953 , test_full_loss:0.82265
save model
Epoch 1 , train_step_loss:0.31059 , train_full_loss:0.36484 , test_step_loss:0.63108 , test_full_loss:0.73274
Epoch 2 , train_step_loss:0.27814 , train_full_loss:0.32452 , test_step_loss:0.55410 , test_full_loss:0.65188
Epoch 3 , train_step_loss:0.25396 , train_full_loss:0.29814 , test_step_loss:0.49082 , test_full_loss:0.58753
Epoch 4 , train_step_loss:0.24053 , train_full_loss:0.28338 , test_step_loss:0.51754 , test_full_loss:0.61865
Epoch 5 , train_step_loss:0.23113 , train_full_loss:0.27209 , test_step_loss:0.56673 , test_full_loss:0.68201
Epoch 6 , train_step_loss:0.22151 , train_full_loss:0.26079 , test_step_loss:0.51753 , test_full_loss:0.60275
Epoch 7 , train_step_loss:0.21170 , train_full_loss:0.24886 , test_step_loss:0.44401 , test_full_loss:0.51780
Epoch 8 , train_step_loss:0.20312 , train_full_loss:0.23873 , test_step_loss:0.39524 , test_full_loss:0.46872
Epoch 9 , train_step_loss:0.19767 , train_full_loss:0.23223 , test_step_loss:0.39254 , test_full_loss:0.45843
Epoch 10 , train_step_loss:0.19187 , train_full_loss:0.22596 , test_step_loss:0.43197 , test_full_loss:0.51276
Epoch 11 , train_step_loss:0.18805 , train_full_loss:0.22093 , test_step_loss:0.43012 , test_full_loss:0.50591
Epoch 12 , train_step_loss:0.18296 , train_full_loss:0.21541 , test_step_loss:0.47104 , test_full_loss:0.55649
Epoch 13 , train_step_loss:0.17768 , train_full_loss:0.20907 , test_step_loss:0.36900 , test_full_loss:0.43768
Epoch 14 , train_step_loss:0.17467 , train_full_loss:0.20546 , test_step_loss:0.39285 , test_full_loss:0.46915
Epoch 15 , train_step_loss:0.17100 , train_full_loss:0.20074 , test_step_loss:0.33456 , test_full_loss:0.39531
Epoch 16 , train_step_loss:0.16534 , train_full_loss:0.19475 , test_step_loss:0.34140 , test_full_loss:0.40681
Epoch 17 , train_step_loss:0.16416 , train_full_loss:0.19272 , test_step_loss:0.44302 , test_full_loss:0.52026
Epoch 18 , train_step_loss:0.15848 , train_full_loss:0.18608 , test_step_loss:0.39922 , test_full_loss:0.48839
Epoch 19 , train_step_loss:0.15498 , train_full_loss:0.18208 , test_step_loss:0.42076 , test_full_loss:0.49806
Epoch 20 , train_step_loss:0.15252 , train_full_loss:0.17933 , test_step_loss:0.36515 , test_full_loss:0.43602
Epoch 21 , train_step_loss:0.14948 , train_full_loss:0.17590 , test_step_loss:0.38079 , test_full_loss:0.45640
Epoch 22 , train_step_loss:0.14675 , train_full_loss:0.17239 , test_step_loss:0.35322 , test_full_loss:0.43448
Epoch 23 , train_step_loss:0.14282 , train_full_loss:0.16769 , test_step_loss:0.37411 , test_full_loss:0.45078
Epoch 24 , train_step_loss:0.13909 , train_full_loss:0.16384 , test_step_loss:0.35240 , test_full_loss:0.42820
Epoch 25 , train_step_loss:0.13756 , train_full_loss:0.16144 , test_step_loss:0.31302 , test_full_loss:0.37162
Epoch 26 , train_step_loss:0.13538 , train_full_loss:0.15877 , test_step_loss:0.30272 , test_full_loss:0.36304
Epoch 27 , train_step_loss:0.12981 , train_full_loss:0.15257 , test_step_loss:0.34475 , test_full_loss:0.40967
Epoch 28 , train_step_loss:0.13122 , train_full_loss:0.15400 , test_step_loss:0.29499 , test_full_loss:0.35592
Epoch 29 , train_step_loss:0.12525 , train_full_loss:0.14742 , test_step_loss:0.32794 , test_full_loss:0.39890
Epoch 30 , train_step_loss:0.12435 , train_full_loss:0.14603 , test_step_loss:0.29914 , test_full_loss:0.36054
Epoch 31 , train_step_loss:0.12256 , train_full_loss:0.14394 , test_step_loss:0.33477 , test_full_loss:0.41819
Epoch 32 , train_step_loss:0.12054 , train_full_loss:0.14116 , test_step_loss:0.27566 , test_full_loss:0.33550
Epoch 33 , train_step_loss:0.11719 , train_full_loss:0.13757 , test_step_loss:0.27577 , test_full_loss:0.34107
Epoch 34 , train_step_loss:0.11624 , train_full_loss:0.13665 , test_step_loss:0.35033 , test_full_loss:0.43163
Epoch 35 , train_step_loss:0.11411 , train_full_loss:0.13400 , test_step_loss:0.32458 , test_full_loss:0.39091
Epoch 36 , train_step_loss:0.11231 , train_full_loss:0.13186 , test_step_loss:0.30651 , test_full_loss:0.36623
Epoch 37 , train_step_loss:0.11026 , train_full_loss:0.12969 , test_step_loss:0.31442 , test_full_loss:0.38549
Epoch 38 , train_step_loss:0.10794 , train_full_loss:0.12706 , test_step_loss:0.26133 , test_full_loss:0.32119
Epoch 39 , train_step_loss:0.10720 , train_full_loss:0.12630 , test_step_loss:0.31541 , test_full_loss:0.39316
Epoch 40 , train_step_loss:0.10528 , train_full_loss:0.12410 , test_step_loss:0.29183 , test_full_loss:0.36122
Epoch 41 , train_step_loss:0.10402 , train_full_loss:0.12245 , test_step_loss:0.26256 , test_full_loss:0.31927
Epoch 42 , train_step_loss:0.10110 , train_full_loss:0.11952 , test_step_loss:0.25409 , test_full_loss:0.31303
Epoch 43 , train_step_loss:0.10056 , train_full_loss:0.11883 , test_step_loss:0.34654 , test_full_loss:0.41369
Epoch 44 , train_step_loss:0.09862 , train_full_loss:0.11651 , test_step_loss:0.27464 , test_full_loss:0.33434
Epoch 45 , train_step_loss:0.09712 , train_full_loss:0.11486 , test_step_loss:0.24961 , test_full_loss:0.30496
Epoch 46 , train_step_loss:0.09592 , train_full_loss:0.11338 , test_step_loss:0.30354 , test_full_loss:0.36619
Epoch 47 , train_step_loss:0.09333 , train_full_loss:0.11093 , test_step_loss:0.29236 , test_full_loss:0.36358
Epoch 48 , train_step_loss:0.09273 , train_full_loss:0.11038 , test_step_loss:0.30815 , test_full_loss:0.37779
Epoch 49 , train_step_loss:0.09284 , train_full_loss:0.11033 , test_step_loss:0.26136 , test_full_loss:0.32016
Epoch 50 , train_step_loss:0.09021 , train_full_loss:0.10777 , test_step_loss:0.29279 , test_full_loss:0.36544
Epoch 51 , train_step_loss:0.09025 , train_full_loss:0.10748 , test_step_loss:0.24963 , test_full_loss:0.30937
Epoch 52 , train_step_loss:0.08834 , train_full_loss:0.10528 , test_step_loss:0.26993 , test_full_loss:0.34234
Epoch 53 , train_step_loss:0.08594 , train_full_loss:0.10299 , test_step_loss:0.24997 , test_full_loss:0.30993
Epoch 54 , train_step_loss:0.08649 , train_full_loss:0.10351 , test_step_loss:0.28902 , test_full_loss:0.35862
Epoch 55 , train_step_loss:0.08514 , train_full_loss:0.10186 , test_step_loss:0.25193 , test_full_loss:0.31309
Epoch 56 , train_step_loss:0.08474 , train_full_loss:0.10111 , test_step_loss:0.24778 , test_full_loss:0.30719
Epoch 57 , train_step_loss:0.08395 , train_full_loss:0.10088 , test_step_loss:0.33908 , test_full_loss:0.42363
Epoch 58 , train_step_loss:0.08505 , train_full_loss:0.10106 , test_step_loss:0.26412 , test_full_loss:0.33093
Epoch 59 , train_step_loss:0.08179 , train_full_loss:0.09802 , test_step_loss:0.26731 , test_full_loss:0.33578
Epoch 60 , train_step_loss:0.07978 , train_full_loss:0.09591 , test_step_loss:0.25879 , test_full_loss:0.32669
Epoch 61 , train_step_loss:0.08081 , train_full_loss:0.09727 , test_step_loss:0.25960 , test_full_loss:0.32608
Epoch 62 , train_step_loss:0.08042 , train_full_loss:0.09648 , test_step_loss:0.26430 , test_full_loss:0.33015
Epoch 63 , train_step_loss:0.07899 , train_full_loss:0.09470 , test_step_loss:0.22352 , test_full_loss:0.28488
Epoch 64 , train_step_loss:0.07867 , train_full_loss:0.09439 , test_step_loss:0.24146 , test_full_loss:0.30375
Epoch 65 , train_step_loss:0.07756 , train_full_loss:0.09341 , test_step_loss:0.26312 , test_full_loss:0.32550
Epoch 66 , train_step_loss:0.07560 , train_full_loss:0.09108 , test_step_loss:0.23421 , test_full_loss:0.29345
Epoch 67 , train_step_loss:0.07529 , train_full_loss:0.09078 , test_step_loss:0.22620 , test_full_loss:0.28094
Epoch 68 , train_step_loss:0.07576 , train_full_loss:0.09104 , test_step_loss:0.24836 , test_full_loss:0.31910
Epoch 69 , train_step_loss:0.07329 , train_full_loss:0.08815 , test_step_loss:0.25454 , test_full_loss:0.31472
Epoch 70 , train_step_loss:0.07409 , train_full_loss:0.08918 , test_step_loss:0.25104 , test_full_loss:0.32826
Epoch 71 , train_step_loss:0.07356 , train_full_loss:0.08852 , test_step_loss:0.22155 , test_full_loss:0.28189
Epoch 72 , train_step_loss:0.07276 , train_full_loss:0.08790 , test_step_loss:0.21670 , test_full_loss:0.27561
Epoch 73 , train_step_loss:0.07225 , train_full_loss:0.08673 , test_step_loss:0.26121 , test_full_loss:0.33547
Epoch 74 , train_step_loss:0.07064 , train_full_loss:0.08576 , test_step_loss:0.22739 , test_full_loss:0.29158
Epoch 75 , train_step_loss:0.07118 , train_full_loss:0.08594 , test_step_loss:0.21388 , test_full_loss:0.27713
Epoch 76 , train_step_loss:0.06921 , train_full_loss:0.08354 , test_step_loss:0.22182 , test_full_loss:0.28175
Epoch 77 , train_step_loss:0.07115 , train_full_loss:0.08563 , test_step_loss:0.20973 , test_full_loss:0.26430
Epoch 78 , train_step_loss:0.06814 , train_full_loss:0.08258 , test_step_loss:0.23052 , test_full_loss:0.28747
Epoch 79 , train_step_loss:0.06962 , train_full_loss:0.08371 , test_step_loss:0.23558 , test_full_loss:0.30268
Epoch 80 , train_step_loss:0.06717 , train_full_loss:0.08114 , test_step_loss:0.23187 , test_full_loss:0.29947
Epoch 81 , train_step_loss:0.06684 , train_full_loss:0.08073 , test_step_loss:0.23691 , test_full_loss:0.29711
Epoch 82 , train_step_loss:0.06644 , train_full_loss:0.08033 , test_step_loss:0.25923 , test_full_loss:0.32108
Epoch 83 , train_step_loss:0.06496 , train_full_loss:0.07871 , test_step_loss:0.21920 , test_full_loss:0.28661
Epoch 84 , train_step_loss:0.06548 , train_full_loss:0.07938 , test_step_loss:0.26181 , test_full_loss:0.33293
Epoch 85 , train_step_loss:0.06600 , train_full_loss:0.07969 , test_step_loss:0.22523 , test_full_loss:0.29449
Epoch 86 , train_step_loss:0.06418 , train_full_loss:0.07768 , test_step_loss:0.22132 , test_full_loss:0.28456
Epoch 87 , train_step_loss:0.06416 , train_full_loss:0.07774 , test_step_loss:0.21963 , test_full_loss:0.27763
Epoch 88 , train_step_loss:0.06297 , train_full_loss:0.07634 , test_step_loss:0.24299 , test_full_loss:0.30993
Epoch 89 , train_step_loss:0.06230 , train_full_loss:0.07558 , test_step_loss:0.20442 , test_full_loss:0.26185
Epoch 90 , train_step_loss:0.06318 , train_full_loss:0.07652 , test_step_loss:0.21126 , test_full_loss:0.26584
Epoch 91 , train_step_loss:0.06235 , train_full_loss:0.07549 , test_step_loss:0.24675 , test_full_loss:0.31893
Epoch 92 , train_step_loss:0.06159 , train_full_loss:0.07488 , test_step_loss:0.22349 , test_full_loss:0.28623
Epoch 93 , train_step_loss:0.06090 , train_full_loss:0.07404 , test_step_loss:0.18308 , test_full_loss:0.23338
Epoch 94 , train_step_loss:0.06084 , train_full_loss:0.07376 , test_step_loss:0.21352 , test_full_loss:0.27369
Epoch 95 , train_step_loss:0.06105 , train_full_loss:0.07420 , test_step_loss:0.22081 , test_full_loss:0.28944
Epoch 96 , train_step_loss:0.06110 , train_full_loss:0.07366 , test_step_loss:0.17131 , test_full_loss:0.21692
Epoch 97 , train_step_loss:0.05960 , train_full_loss:0.07226 , test_step_loss:0.21467 , test_full_loss:0.27278
Epoch 98 , train_step_loss:0.05992 , train_full_loss:0.07269 , test_step_loss:0.22712 , test_full_loss:0.28987
Epoch 99 , train_step_loss:0.05800 , train_full_loss:0.07032 , test_step_loss:0.20247 , test_full_loss:0.26090
Epoch 100 , train_step_loss:0.05738 , train_full_loss:0.06976 , test_step_loss:0.18335 , test_full_loss:0.23674
save model
Epoch 101 , train_step_loss:0.05795 , train_full_loss:0.07026 , test_step_loss:0.19506 , test_full_loss:0.25474
Epoch 102 , train_step_loss:0.05693 , train_full_loss:0.06924 , test_step_loss:0.17954 , test_full_loss:0.23004
Epoch 103 , train_step_loss:0.05777 , train_full_loss:0.07024 , test_step_loss:0.28114 , test_full_loss:0.36048
Epoch 104 , train_step_loss:0.05701 , train_full_loss:0.06919 , test_step_loss:0.22605 , test_full_loss:0.28413
Epoch 105 , train_step_loss:0.05614 , train_full_loss:0.06830 , test_step_loss:0.22224 , test_full_loss:0.28800
Epoch 106 , train_step_loss:0.05607 , train_full_loss:0.06832 , test_step_loss:0.22336 , test_full_loss:0.28536
Epoch 107 , train_step_loss:0.05616 , train_full_loss:0.06787 , test_step_loss:0.18282 , test_full_loss:0.23365
Epoch 108 , train_step_loss:0.05498 , train_full_loss:0.06686 , test_step_loss:0.17294 , test_full_loss:0.22161
Epoch 109 , train_step_loss:0.05433 , train_full_loss:0.06590 , test_step_loss:0.16999 , test_full_loss:0.22039
Epoch 110 , train_step_loss:0.05411 , train_full_loss:0.06581 , test_step_loss:0.19856 , test_full_loss:0.25199
Epoch 111 , train_step_loss:0.05370 , train_full_loss:0.06527 , test_step_loss:0.18508 , test_full_loss:0.23810
Epoch 112 , train_step_loss:0.05311 , train_full_loss:0.06479 , test_step_loss:0.18524 , test_full_loss:0.23963
Epoch 113 , train_step_loss:0.05306 , train_full_loss:0.06448 , test_step_loss:0.20589 , test_full_loss:0.26215
Epoch 114 , train_step_loss:0.05244 , train_full_loss:0.06382 , test_step_loss:0.16615 , test_full_loss:0.20994
Epoch 115 , train_step_loss:0.05273 , train_full_loss:0.06412 , test_step_loss:0.17108 , test_full_loss:0.22061
Epoch 116 , train_step_loss:0.05334 , train_full_loss:0.06476 , test_step_loss:0.20168 , test_full_loss:0.26284
Epoch 117 , train_step_loss:0.05182 , train_full_loss:0.06310 , test_step_loss:0.19040 , test_full_loss:0.25033
Epoch 118 , train_step_loss:0.05221 , train_full_loss:0.06341 , test_step_loss:0.24498 , test_full_loss:0.32879
Epoch 119 , train_step_loss:0.05148 , train_full_loss:0.06275 , test_step_loss:0.18095 , test_full_loss:0.23784
Epoch 120 , train_step_loss:0.05233 , train_full_loss:0.06338 , test_step_loss:0.16552 , test_full_loss:0.21176
Epoch 121 , train_step_loss:0.05144 , train_full_loss:0.06274 , test_step_loss:0.17914 , test_full_loss:0.23399
Epoch 122 , train_step_loss:0.05033 , train_full_loss:0.06143 , test_step_loss:0.19617 , test_full_loss:0.26073
Epoch 123 , train_step_loss:0.05075 , train_full_loss:0.06177 , test_step_loss:0.19246 , test_full_loss:0.25889
Epoch 124 , train_step_loss:0.04993 , train_full_loss:0.06063 , test_step_loss:0.18579 , test_full_loss:0.23914
Epoch 125 , train_step_loss:0.04996 , train_full_loss:0.06059 , test_step_loss:0.16570 , test_full_loss:0.21107
Epoch 126 , train_step_loss:0.04812 , train_full_loss:0.05868 , test_step_loss:0.19267 , test_full_loss:0.25762
Epoch 127 , train_step_loss:0.04849 , train_full_loss:0.05915 , test_step_loss:0.18588 , test_full_loss:0.24228
Epoch 128 , train_step_loss:0.04879 , train_full_loss:0.05919 , test_step_loss:0.24080 , test_full_loss:0.31253
Epoch 129 , train_step_loss:0.04892 , train_full_loss:0.05949 , test_step_loss:0.18551 , test_full_loss:0.24441
Epoch 130 , train_step_loss:0.04819 , train_full_loss:0.05860 , test_step_loss:0.17091 , test_full_loss:0.22292
Epoch 131 , train_step_loss:0.04776 , train_full_loss:0.05812 , test_step_loss:0.20605 , test_full_loss:0.27871
Epoch 132 , train_step_loss:0.04744 , train_full_loss:0.05771 , test_step_loss:0.16574 , test_full_loss:0.21870
Epoch 133 , train_step_loss:0.04651 , train_full_loss:0.05674 , test_step_loss:0.20376 , test_full_loss:0.27488
Epoch 134 , train_step_loss:0.04647 , train_full_loss:0.05663 , test_step_loss:0.18444 , test_full_loss:0.24525
Epoch 135 , train_step_loss:0.04644 , train_full_loss:0.05652 , test_step_loss:0.19340 , test_full_loss:0.25227
Epoch 136 , train_step_loss:0.04677 , train_full_loss:0.05690 , test_step_loss:0.16644 , test_full_loss:0.21688
Epoch 137 , train_step_loss:0.04512 , train_full_loss:0.05498 , test_step_loss:0.16099 , test_full_loss:0.20820
Epoch 138 , train_step_loss:0.04598 , train_full_loss:0.05592 , test_step_loss:0.16469 , test_full_loss:0.21337
Epoch 139 , train_step_loss:0.04437 , train_full_loss:0.05418 , test_step_loss:0.17686 , test_full_loss:0.23821
Epoch 140 , train_step_loss:0.04532 , train_full_loss:0.05509 , test_step_loss:0.17384 , test_full_loss:0.22657
Epoch 141 , train_step_loss:0.04519 , train_full_loss:0.05495 , test_step_loss:0.15994 , test_full_loss:0.20696
Epoch 142 , train_step_loss:0.04506 , train_full_loss:0.05482 , test_step_loss:0.14887 , test_full_loss:0.19454
Epoch 143 , train_step_loss:0.04453 , train_full_loss:0.05412 , test_step_loss:0.19127 , test_full_loss:0.25275
Epoch 144 , train_step_loss:0.04341 , train_full_loss:0.05283 , test_step_loss:0.18377 , test_full_loss:0.24695
Epoch 145 , train_step_loss:0.04350 , train_full_loss:0.05305 , test_step_loss:0.15901 , test_full_loss:0.20860
Epoch 146 , train_step_loss:0.04354 , train_full_loss:0.05282 , test_step_loss:0.14093 , test_full_loss:0.18604
Epoch 147 , train_step_loss:0.04255 , train_full_loss:0.05171 , test_step_loss:0.14936 , test_full_loss:0.19599
Epoch 148 , train_step_loss:0.04314 , train_full_loss:0.05261 , test_step_loss:0.17576 , test_full_loss:0.22379
Epoch 149 , train_step_loss:0.04332 , train_full_loss:0.05252 , test_step_loss:0.15808 , test_full_loss:0.20569
Epoch 150 , train_step_loss:0.04255 , train_full_loss:0.05191 , test_step_loss:0.18262 , test_full_loss:0.24003
Epoch 151 , train_step_loss:0.04216 , train_full_loss:0.05141 , test_step_loss:0.16110 , test_full_loss:0.21804
Epoch 152 , train_step_loss:0.04187 , train_full_loss:0.05095 , test_step_loss:0.14140 , test_full_loss:0.18638
Epoch 153 , train_step_loss:0.04183 , train_full_loss:0.05087 , test_step_loss:0.18313 , test_full_loss:0.24273
Epoch 154 , train_step_loss:0.04210 , train_full_loss:0.05114 , test_step_loss:0.14731 , test_full_loss:0.19265
Epoch 155 , train_step_loss:0.04155 , train_full_loss:0.05045 , test_step_loss:0.15888 , test_full_loss:0.21048
Epoch 156 , train_step_loss:0.04039 , train_full_loss:0.04917 , test_step_loss:0.17774 , test_full_loss:0.23090
Epoch 157 , train_step_loss:0.04106 , train_full_loss:0.04983 , test_step_loss:0.17395 , test_full_loss:0.23454
Epoch 158 , train_step_loss:0.04009 , train_full_loss:0.04894 , test_step_loss:0.17912 , test_full_loss:0.24770
Epoch 159 , train_step_loss:0.04041 , train_full_loss:0.04897 , test_step_loss:0.16894 , test_full_loss:0.22202
Epoch 160 , train_step_loss:0.04022 , train_full_loss:0.04892 , test_step_loss:0.15293 , test_full_loss:0.20052
Epoch 161 , train_step_loss:0.04124 , train_full_loss:0.04991 , test_step_loss:0.21717 , test_full_loss:0.29564
Epoch 162 , train_step_loss:0.04041 , train_full_loss:0.04909 , test_step_loss:0.16823 , test_full_loss:0.22688
Epoch 163 , train_step_loss:0.03902 , train_full_loss:0.04744 , test_step_loss:0.15888 , test_full_loss:0.21383
Epoch 164 , train_step_loss:0.03897 , train_full_loss:0.04740 , test_step_loss:0.14238 , test_full_loss:0.18959
Epoch 165 , train_step_loss:0.03917 , train_full_loss:0.04762 , test_step_loss:0.16660 , test_full_loss:0.21696
Epoch 166 , train_step_loss:0.04027 , train_full_loss:0.04881 , test_step_loss:0.16504 , test_full_loss:0.21328
Epoch 167 , train_step_loss:0.03797 , train_full_loss:0.04618 , test_step_loss:0.15508 , test_full_loss:0.20470
Epoch 168 , train_step_loss:0.03785 , train_full_loss:0.04602 , test_step_loss:0.14190 , test_full_loss:0.18663
Epoch 169 , train_step_loss:0.03848 , train_full_loss:0.04685 , test_step_loss:0.17481 , test_full_loss:0.23425
Epoch 170 , train_step_loss:0.03909 , train_full_loss:0.04718 , test_step_loss:0.19799 , test_full_loss:0.26725
Epoch 171 , train_step_loss:0.03820 , train_full_loss:0.04643 , test_step_loss:0.14289 , test_full_loss:0.19054
Epoch 172 , train_step_loss:0.03678 , train_full_loss:0.04481 , test_step_loss:0.18727 , test_full_loss:0.25300
Epoch 173 , train_step_loss:0.03788 , train_full_loss:0.04585 , test_step_loss:0.14897 , test_full_loss:0.19554
Epoch 174 , train_step_loss:0.03794 , train_full_loss:0.04607 , test_step_loss:0.15191 , test_full_loss:0.20206
Epoch 175 , train_step_loss:0.03716 , train_full_loss:0.04513 , test_step_loss:0.17172 , test_full_loss:0.23502
Epoch 176 , train_step_loss:0.03696 , train_full_loss:0.04493 , test_step_loss:0.14536 , test_full_loss:0.19466
Epoch 177 , train_step_loss:0.03629 , train_full_loss:0.04417 , test_step_loss:0.12966 , test_full_loss:0.16940
Epoch 178 , train_step_loss:0.03741 , train_full_loss:0.04540 , test_step_loss:0.16562 , test_full_loss:0.22901
Epoch 179 , train_step_loss:0.03623 , train_full_loss:0.04403 , test_step_loss:0.14490 , test_full_loss:0.19164
Epoch 180 , train_step_loss:0.03629 , train_full_loss:0.04413 , test_step_loss:0.13377 , test_full_loss:0.17771
Epoch 181 , train_step_loss:0.03569 , train_full_loss:0.04344 , test_step_loss:0.14505 , test_full_loss:0.19336
Epoch 182 , train_step_loss:0.03567 , train_full_loss:0.04321 , test_step_loss:0.15226 , test_full_loss:0.20281
Epoch 183 , train_step_loss:0.03565 , train_full_loss:0.04334 , test_step_loss:0.15080 , test_full_loss:0.19921
Epoch 184 , train_step_loss:0.03612 , train_full_loss:0.04389 , test_step_loss:0.13126 , test_full_loss:0.17636
Epoch 185 , train_step_loss:0.03537 , train_full_loss:0.04296 , test_step_loss:0.15791 , test_full_loss:0.21089
Epoch 186 , train_step_loss:0.03532 , train_full_loss:0.04288 , test_step_loss:0.19989 , test_full_loss:0.26881
Epoch 187 , train_step_loss:0.03525 , train_full_loss:0.04288 , test_step_loss:0.18298 , test_full_loss:0.24584
Epoch 188 , train_step_loss:0.03540 , train_full_loss:0.04282 , test_step_loss:0.12570 , test_full_loss:0.16865
Epoch 189 , train_step_loss:0.03419 , train_full_loss:0.04138 , test_step_loss:0.14704 , test_full_loss:0.20115
Epoch 190 , train_step_loss:0.03417 , train_full_loss:0.04141 , test_step_loss:0.13463 , test_full_loss:0.18267
Epoch 191 , train_step_loss:0.03489 , train_full_loss:0.04225 , test_step_loss:0.12725 , test_full_loss:0.16875
Epoch 192 , train_step_loss:0.03402 , train_full_loss:0.04142 , test_step_loss:0.14300 , test_full_loss:0.19088
Epoch 193 , train_step_loss:0.03446 , train_full_loss:0.04182 , test_step_loss:0.14076 , test_full_loss:0.18725
Epoch 194 , train_step_loss:0.03452 , train_full_loss:0.04174 , test_step_loss:0.12632 , test_full_loss:0.16722
Epoch 195 , train_step_loss:0.03377 , train_full_loss:0.04090 , test_step_loss:0.13059 , test_full_loss:0.17128
Epoch 196 , train_step_loss:0.03281 , train_full_loss:0.03984 , test_step_loss:0.14341 , test_full_loss:0.18892
Epoch 197 , train_step_loss:0.03394 , train_full_loss:0.04103 , test_step_loss:0.13008 , test_full_loss:0.17480
Epoch 198 , train_step_loss:0.03380 , train_full_loss:0.04095 , test_step_loss:0.17109 , test_full_loss:0.23383
Epoch 199 , train_step_loss:0.03306 , train_full_loss:0.04013 , test_step_loss:0.13092 , test_full_loss:0.17441
Epoch 200 , train_step_loss:0.03374 , train_full_loss:0.04080 , test_step_loss:0.14064 , test_full_loss:0.19166
save model
Epoch 201 , train_step_loss:0.03281 , train_full_loss:0.03983 , test_step_loss:0.14097 , test_full_loss:0.18763
Epoch 202 , train_step_loss:0.03388 , train_full_loss:0.04101 , test_step_loss:0.15044 , test_full_loss:0.20293
Epoch 203 , train_step_loss:0.03366 , train_full_loss:0.04077 , test_step_loss:0.16193 , test_full_loss:0.22186
Epoch 204 , train_step_loss:0.03259 , train_full_loss:0.03939 , test_step_loss:0.15165 , test_full_loss:0.20924
Epoch 205 , train_step_loss:0.03330 , train_full_loss:0.04038 , test_step_loss:0.13957 , test_full_loss:0.18655
Epoch 206 , train_step_loss:0.03175 , train_full_loss:0.03844 , test_step_loss:0.13589 , test_full_loss:0.18371
Epoch 207 , train_step_loss:0.03249 , train_full_loss:0.03933 , test_step_loss:0.14027 , test_full_loss:0.19319
Epoch 208 , train_step_loss:0.03221 , train_full_loss:0.03892 , test_step_loss:0.12411 , test_full_loss:0.16681
Epoch 209 , train_step_loss:0.03209 , train_full_loss:0.03890 , test_step_loss:0.12291 , test_full_loss:0.16268
Epoch 210 , train_step_loss:0.03221 , train_full_loss:0.03889 , test_step_loss:0.13223 , test_full_loss:0.17661
Epoch 211 , train_step_loss:0.03132 , train_full_loss:0.03797 , test_step_loss:0.14509 , test_full_loss:0.20083
Epoch 212 , train_step_loss:0.03219 , train_full_loss:0.03896 , test_step_loss:0.12627 , test_full_loss:0.16853
Epoch 213 , train_step_loss:0.03158 , train_full_loss:0.03826 , test_step_loss:0.12411 , test_full_loss:0.16359
Epoch 214 , train_step_loss:0.03076 , train_full_loss:0.03735 , test_step_loss:0.11584 , test_full_loss:0.15450
Epoch 215 , train_step_loss:0.03081 , train_full_loss:0.03734 , test_step_loss:0.14416 , test_full_loss:0.19902
Epoch 216 , train_step_loss:0.03172 , train_full_loss:0.03838 , test_step_loss:0.11961 , test_full_loss:0.16079
Epoch 217 , train_step_loss:0.03190 , train_full_loss:0.03851 , test_step_loss:0.12589 , test_full_loss:0.16726
Epoch 218 , train_step_loss:0.03033 , train_full_loss:0.03673 , test_step_loss:0.13023 , test_full_loss:0.17774
Epoch 219 , train_step_loss:0.03074 , train_full_loss:0.03724 , test_step_loss:0.12008 , test_full_loss:0.16008
Epoch 220 , train_step_loss:0.03043 , train_full_loss:0.03676 , test_step_loss:0.15084 , test_full_loss:0.21148
Epoch 221 , train_step_loss:0.03049 , train_full_loss:0.03686 , test_step_loss:0.14105 , test_full_loss:0.18848
Epoch 222 , train_step_loss:0.03000 , train_full_loss:0.03634 , test_step_loss:0.11584 , test_full_loss:0.15620
Epoch 223 , train_step_loss:0.03022 , train_full_loss:0.03668 , test_step_loss:0.13248 , test_full_loss:0.17572
Epoch 224 , train_step_loss:0.03048 , train_full_loss:0.03688 , test_step_loss:0.14526 , test_full_loss:0.19685
Epoch 225 , train_step_loss:0.03104 , train_full_loss:0.03740 , test_step_loss:0.12098 , test_full_loss:0.16191
Epoch 226 , train_step_loss:0.02896 , train_full_loss:0.03504 , test_step_loss:0.11699 , test_full_loss:0.15387
Epoch 227 , train_step_loss:0.02956 , train_full_loss:0.03575 , test_step_loss:0.12176 , test_full_loss:0.16646
Epoch 228 , train_step_loss:0.03023 , train_full_loss:0.03659 , test_step_loss:0.13901 , test_full_loss:0.18598
Epoch 229 , train_step_loss:0.02961 , train_full_loss:0.03581 , test_step_loss:0.11581 , test_full_loss:0.15531
Epoch 230 , train_step_loss:0.02894 , train_full_loss:0.03493 , test_step_loss:0.11560 , test_full_loss:0.15309
Epoch 231 , train_step_loss:0.02930 , train_full_loss:0.03538 , test_step_loss:0.12096 , test_full_loss:0.16174
Epoch 232 , train_step_loss:0.02986 , train_full_loss:0.03606 , test_step_loss:0.11892 , test_full_loss:0.16057
Epoch 233 , train_step_loss:0.02908 , train_full_loss:0.03510 , test_step_loss:0.11288 , test_full_loss:0.15134
Epoch 234 , train_step_loss:0.02867 , train_full_loss:0.03464 , test_step_loss:0.16616 , test_full_loss:0.22891
Epoch 235 , train_step_loss:0.02864 , train_full_loss:0.03459 , test_step_loss:0.11347 , test_full_loss:0.15065
Epoch 236 , train_step_loss:0.02911 , train_full_loss:0.03506 , test_step_loss:0.11833 , test_full_loss:0.15930
Epoch 237 , train_step_loss:0.02848 , train_full_loss:0.03442 , test_step_loss:0.11744 , test_full_loss:0.15578
Epoch 238 , train_step_loss:0.02871 , train_full_loss:0.03475 , test_step_loss:0.11130 , test_full_loss:0.14725
Epoch 239 , train_step_loss:0.02818 , train_full_loss:0.03409 , test_step_loss:0.12913 , test_full_loss:0.17399
Epoch 240 , train_step_loss:0.02826 , train_full_loss:0.03405 , test_step_loss:0.12373 , test_full_loss:0.16434
Epoch 241 , train_step_loss:0.02852 , train_full_loss:0.03425 , test_step_loss:0.16843 , test_full_loss:0.23587
Epoch 242 , train_step_loss:0.02824 , train_full_loss:0.03416 , test_step_loss:0.13178 , test_full_loss:0.17735
Epoch 243 , train_step_loss:0.02795 , train_full_loss:0.03384 , test_step_loss:0.11678 , test_full_loss:0.15659
Epoch 244 , train_step_loss:0.02782 , train_full_loss:0.03362 , test_step_loss:0.12173 , test_full_loss:0.16282
Epoch 245 , train_step_loss:0.02768 , train_full_loss:0.03330 , test_step_loss:0.11803 , test_full_loss:0.16152
Epoch 246 , train_step_loss:0.02792 , train_full_loss:0.03360 , test_step_loss:0.12414 , test_full_loss:0.16667
Epoch 247 , train_step_loss:0.02730 , train_full_loss:0.03301 , test_step_loss:0.11334 , test_full_loss:0.15127
Epoch 248 , train_step_loss:0.02713 , train_full_loss:0.03276 , test_step_loss:0.12921 , test_full_loss:0.17399
Epoch 249 , train_step_loss:0.02774 , train_full_loss:0.03347 , test_step_loss:0.13597 , test_full_loss:0.18613
Epoch 250 , train_step_loss:0.02807 , train_full_loss:0.03380 , test_step_loss:0.12586 , test_full_loss:0.17028
Epoch 251 , train_step_loss:0.02677 , train_full_loss:0.03232 , test_step_loss:0.11348 , test_full_loss:0.15215
Epoch 252 , train_step_loss:0.02781 , train_full_loss:0.03351 , test_step_loss:0.13391 , test_full_loss:0.18559
Epoch 253 , train_step_loss:0.02688 , train_full_loss:0.03242 , test_step_loss:0.10958 , test_full_loss:0.14855
Epoch 254 , train_step_loss:0.02673 , train_full_loss:0.03217 , test_step_loss:0.11185 , test_full_loss:0.15447
Epoch 255 , train_step_loss:0.02660 , train_full_loss:0.03206 , test_step_loss:0.11289 , test_full_loss:0.15346
Epoch 256 , train_step_loss:0.02670 , train_full_loss:0.03217 , test_step_loss:0.10954 , test_full_loss:0.14960
Epoch 257 , train_step_loss:0.02644 , train_full_loss:0.03193 , test_step_loss:0.11709 , test_full_loss:0.15872
Epoch 258 , train_step_loss:0.02663 , train_full_loss:0.03211 , test_step_loss:0.11472 , test_full_loss:0.15450
Epoch 259 , train_step_loss:0.02602 , train_full_loss:0.03145 , test_step_loss:0.10629 , test_full_loss:0.14351
Epoch 260 , train_step_loss:0.02614 , train_full_loss:0.03157 , test_step_loss:0.11051 , test_full_loss:0.14730
Epoch 261 , train_step_loss:0.02617 , train_full_loss:0.03155 , test_step_loss:0.13863 , test_full_loss:0.19172
Epoch 262 , train_step_loss:0.02640 , train_full_loss:0.03176 , test_step_loss:0.11216 , test_full_loss:0.15374
Epoch 263 , train_step_loss:0.02625 , train_full_loss:0.03156 , test_step_loss:0.10696 , test_full_loss:0.14320
Epoch 264 , train_step_loss:0.02585 , train_full_loss:0.03116 , test_step_loss:0.11430 , test_full_loss:0.15492
Epoch 265 , train_step_loss:0.02622 , train_full_loss:0.03152 , test_step_loss:0.10713 , test_full_loss:0.14479
Epoch 266 , train_step_loss:0.02533 , train_full_loss:0.03047 , test_step_loss:0.10789 , test_full_loss:0.14653
Epoch 267 , train_step_loss:0.02563 , train_full_loss:0.03084 , test_step_loss:0.13995 , test_full_loss:0.19312
Epoch 268 , train_step_loss:0.02571 , train_full_loss:0.03100 , test_step_loss:0.10829 , test_full_loss:0.14517
Epoch 269 , train_step_loss:0.02527 , train_full_loss:0.03040 , test_step_loss:0.10649 , test_full_loss:0.14429
Epoch 270 , train_step_loss:0.02502 , train_full_loss:0.03000 , test_step_loss:0.10909 , test_full_loss:0.14734
Epoch 271 , train_step_loss:0.02521 , train_full_loss:0.03026 , test_step_loss:0.11658 , test_full_loss:0.15901
Epoch 272 , train_step_loss:0.02560 , train_full_loss:0.03077 , test_step_loss:0.11548 , test_full_loss:0.15734
Epoch 273 , train_step_loss:0.02559 , train_full_loss:0.03072 , test_step_loss:0.12609 , test_full_loss:0.17709
Epoch 274 , train_step_loss:0.02449 , train_full_loss:0.02944 , test_step_loss:0.11951 , test_full_loss:0.16480
Epoch 275 , train_step_loss:0.02466 , train_full_loss:0.02973 , test_step_loss:0.10258 , test_full_loss:0.13899
Epoch 276 , train_step_loss:0.02504 , train_full_loss:0.03011 , test_step_loss:0.10448 , test_full_loss:0.14301
Epoch 277 , train_step_loss:0.02465 , train_full_loss:0.02963 , test_step_loss:0.10566 , test_full_loss:0.14267
Epoch 278 , train_step_loss:0.02434 , train_full_loss:0.02922 , test_step_loss:0.10184 , test_full_loss:0.13751
Epoch 279 , train_step_loss:0.02466 , train_full_loss:0.02964 , test_step_loss:0.11912 , test_full_loss:0.16315
Epoch 280 , train_step_loss:0.02461 , train_full_loss:0.02958 , test_step_loss:0.10221 , test_full_loss:0.13592
Epoch 281 , train_step_loss:0.02453 , train_full_loss:0.02945 , test_step_loss:0.11346 , test_full_loss:0.15590
Epoch 282 , train_step_loss:0.02483 , train_full_loss:0.02981 , test_step_loss:0.12190 , test_full_loss:0.16277
Epoch 283 , train_step_loss:0.02421 , train_full_loss:0.02903 , test_step_loss:0.11651 , test_full_loss:0.15979
Epoch 284 , train_step_loss:0.02396 , train_full_loss:0.02875 , test_step_loss:0.10900 , test_full_loss:0.14735
Epoch 285 , train_step_loss:0.02448 , train_full_loss:0.02945 , test_step_loss:0.09939 , test_full_loss:0.13344
Epoch 286 , train_step_loss:0.02389 , train_full_loss:0.02859 , test_step_loss:0.10612 , test_full_loss:0.14475
Epoch 287 , train_step_loss:0.02345 , train_full_loss:0.02803 , test_step_loss:0.12453 , test_full_loss:0.17531
Epoch 288 , train_step_loss:0.02407 , train_full_loss:0.02878 , test_step_loss:0.09696 , test_full_loss:0.13096
Epoch 289 , train_step_loss:0.02333 , train_full_loss:0.02796 , test_step_loss:0.09677 , test_full_loss:0.12880
Epoch 290 , train_step_loss:0.02374 , train_full_loss:0.02839 , test_step_loss:0.11808 , test_full_loss:0.16418
Epoch 291 , train_step_loss:0.02343 , train_full_loss:0.02812 , test_step_loss:0.14534 , test_full_loss:0.20490
Epoch 292 , train_step_loss:0.02382 , train_full_loss:0.02852 , test_step_loss:0.09885 , test_full_loss:0.13347
Epoch 293 , train_step_loss:0.02304 , train_full_loss:0.02766 , test_step_loss:0.09525 , test_full_loss:0.12795
Epoch 294 , train_step_loss:0.02327 , train_full_loss:0.02783 , test_step_loss:0.10829 , test_full_loss:0.14622
Epoch 295 , train_step_loss:0.02315 , train_full_loss:0.02778 , test_step_loss:0.09945 , test_full_loss:0.13476