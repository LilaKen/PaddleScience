W1029 22:19:36.564289 880429 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 12.2, Runtime API Version: 12.0
W1029 22:19:36.564832 880429 gpu_resources.cc:164] device: 0, cuDNN Version: 9.5.
Dataloading is over.
Namespace(lr=0.001, epochs=500, weight_decay=1e-05, model='Transolver_Structured_Mesh_2D', n_hidden=128, n_layers=8, n_heads=8, batch_size=4, gpu=0, max_grad_norm=0.1, downsample=5, mlp_ratio=1, dropout=0.0, ntrain=1000, unified_pos=1, ref=8, slice_num=64, eval=0, save_name='darcy_UniPDE', data_path='data/fno')
Model(
  (preprocess): MLP(
    (linear_pre): Sequential(
      (0): Linear(in_features=65, out_features=256, dtype=None)
      (1): GELU(approximate=False)
    )
    (linear_post): Linear(in_features=256, out_features=128, dtype=None)
    (linears): LayerList()
  )
  (blocks): LayerList(
    (0): Transolver_block(
      (ln_1): LayerNorm(normalized_shape=[128], epsilon=1e-05)
      (Attn): Physics_Attention_Structured_Mesh_2D(
        (softmax): Softmax(axis=-1)
        (dropout): Dropout(p=0.0, axis=None, mode=upscale_in_train)
        (in_project_x): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (in_project_fx): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (in_project_slice): Linear(in_features=16, out_features=64, dtype=None)
        (to_q): Linear(in_features=16, out_features=16, dtype=None)
        (to_k): Linear(in_features=16, out_features=16, dtype=None)
        (to_v): Linear(in_features=16, out_features=16, dtype=None)
        (to_out): Sequential(
          (0): Linear(in_features=128, out_features=128, dtype=None)
          (1): Dropout(p=0.0, axis=None, mode=upscale_in_train)
        )
      )
      (ln_2): LayerNorm(normalized_shape=[128], epsilon=1e-05)
      (mlp): MLP(
        (linear_pre): Sequential(
          (0): Linear(in_features=128, out_features=128, dtype=None)
          (1): GELU(approximate=False)
        )
        (linear_post): Linear(in_features=128, out_features=128, dtype=None)
        (linears): LayerList()
      )
    )
    (1): Transolver_block(
      (ln_1): LayerNorm(normalized_shape=[128], epsilon=1e-05)
      (Attn): Physics_Attention_Structured_Mesh_2D(
        (softmax): Softmax(axis=-1)
        (dropout): Dropout(p=0.0, axis=None, mode=upscale_in_train)
        (in_project_x): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (in_project_fx): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (in_project_slice): Linear(in_features=16, out_features=64, dtype=None)
        (to_q): Linear(in_features=16, out_features=16, dtype=None)
        (to_k): Linear(in_features=16, out_features=16, dtype=None)
        (to_v): Linear(in_features=16, out_features=16, dtype=None)
        (to_out): Sequential(
          (0): Linear(in_features=128, out_features=128, dtype=None)
          (1): Dropout(p=0.0, axis=None, mode=upscale_in_train)
        )
      )
      (ln_2): LayerNorm(normalized_shape=[128], epsilon=1e-05)
      (mlp): MLP(
        (linear_pre): Sequential(
          (0): Linear(in_features=128, out_features=128, dtype=None)
          (1): GELU(approximate=False)
        )
        (linear_post): Linear(in_features=128, out_features=128, dtype=None)
        (linears): LayerList()
      )
    )
    (2): Transolver_block(
      (ln_1): LayerNorm(normalized_shape=[128], epsilon=1e-05)
      (Attn): Physics_Attention_Structured_Mesh_2D(
        (softmax): Softmax(axis=-1)
        (dropout): Dropout(p=0.0, axis=None, mode=upscale_in_train)
        (in_project_x): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (in_project_fx): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (in_project_slice): Linear(in_features=16, out_features=64, dtype=None)
        (to_q): Linear(in_features=16, out_features=16, dtype=None)
        (to_k): Linear(in_features=16, out_features=16, dtype=None)
        (to_v): Linear(in_features=16, out_features=16, dtype=None)
        (to_out): Sequential(
          (0): Linear(in_features=128, out_features=128, dtype=None)
          (1): Dropout(p=0.0, axis=None, mode=upscale_in_train)
        )
      )
      (ln_2): LayerNorm(normalized_shape=[128], epsilon=1e-05)
      (mlp): MLP(
        (linear_pre): Sequential(
          (0): Linear(in_features=128, out_features=128, dtype=None)
          (1): GELU(approximate=False)
        )
        (linear_post): Linear(in_features=128, out_features=128, dtype=None)
        (linears): LayerList()
      )
    )
    (3): Transolver_block(
      (ln_1): LayerNorm(normalized_shape=[128], epsilon=1e-05)
      (Attn): Physics_Attention_Structured_Mesh_2D(
        (softmax): Softmax(axis=-1)
        (dropout): Dropout(p=0.0, axis=None, mode=upscale_in_train)
        (in_project_x): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (in_project_fx): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (in_project_slice): Linear(in_features=16, out_features=64, dtype=None)
        (to_q): Linear(in_features=16, out_features=16, dtype=None)
        (to_k): Linear(in_features=16, out_features=16, dtype=None)
        (to_v): Linear(in_features=16, out_features=16, dtype=None)
        (to_out): Sequential(
          (0): Linear(in_features=128, out_features=128, dtype=None)
          (1): Dropout(p=0.0, axis=None, mode=upscale_in_train)
        )
      )
      (ln_2): LayerNorm(normalized_shape=[128], epsilon=1e-05)
      (mlp): MLP(
        (linear_pre): Sequential(
          (0): Linear(in_features=128, out_features=128, dtype=None)
          (1): GELU(approximate=False)
        )
        (linear_post): Linear(in_features=128, out_features=128, dtype=None)
        (linears): LayerList()
      )
    )
    (4): Transolver_block(
      (ln_1): LayerNorm(normalized_shape=[128], epsilon=1e-05)
      (Attn): Physics_Attention_Structured_Mesh_2D(
        (softmax): Softmax(axis=-1)
        (dropout): Dropout(p=0.0, axis=None, mode=upscale_in_train)
        (in_project_x): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (in_project_fx): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (in_project_slice): Linear(in_features=16, out_features=64, dtype=None)
        (to_q): Linear(in_features=16, out_features=16, dtype=None)
        (to_k): Linear(in_features=16, out_features=16, dtype=None)
        (to_v): Linear(in_features=16, out_features=16, dtype=None)
        (to_out): Sequential(
          (0): Linear(in_features=128, out_features=128, dtype=None)
          (1): Dropout(p=0.0, axis=None, mode=upscale_in_train)
        )
      )
      (ln_2): LayerNorm(normalized_shape=[128], epsilon=1e-05)
      (mlp): MLP(
        (linear_pre): Sequential(
          (0): Linear(in_features=128, out_features=128, dtype=None)
          (1): GELU(approximate=False)
        )
        (linear_post): Linear(in_features=128, out_features=128, dtype=None)
        (linears): LayerList()
      )
    )
    (5): Transolver_block(
      (ln_1): LayerNorm(normalized_shape=[128], epsilon=1e-05)
      (Attn): Physics_Attention_Structured_Mesh_2D(
        (softmax): Softmax(axis=-1)
        (dropout): Dropout(p=0.0, axis=None, mode=upscale_in_train)
        (in_project_x): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (in_project_fx): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (in_project_slice): Linear(in_features=16, out_features=64, dtype=None)
        (to_q): Linear(in_features=16, out_features=16, dtype=None)
        (to_k): Linear(in_features=16, out_features=16, dtype=None)
        (to_v): Linear(in_features=16, out_features=16, dtype=None)
        (to_out): Sequential(
          (0): Linear(in_features=128, out_features=128, dtype=None)
          (1): Dropout(p=0.0, axis=None, mode=upscale_in_train)
        )
      )
      (ln_2): LayerNorm(normalized_shape=[128], epsilon=1e-05)
      (mlp): MLP(
        (linear_pre): Sequential(
          (0): Linear(in_features=128, out_features=128, dtype=None)
          (1): GELU(approximate=False)
        )
        (linear_post): Linear(in_features=128, out_features=128, dtype=None)
        (linears): LayerList()
      )
    )
    (6): Transolver_block(
      (ln_1): LayerNorm(normalized_shape=[128], epsilon=1e-05)
      (Attn): Physics_Attention_Structured_Mesh_2D(
        (softmax): Softmax(axis=-1)
        (dropout): Dropout(p=0.0, axis=None, mode=upscale_in_train)
        (in_project_x): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (in_project_fx): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (in_project_slice): Linear(in_features=16, out_features=64, dtype=None)
        (to_q): Linear(in_features=16, out_features=16, dtype=None)
        (to_k): Linear(in_features=16, out_features=16, dtype=None)
        (to_v): Linear(in_features=16, out_features=16, dtype=None)
        (to_out): Sequential(
          (0): Linear(in_features=128, out_features=128, dtype=None)
          (1): Dropout(p=0.0, axis=None, mode=upscale_in_train)
        )
      )
      (ln_2): LayerNorm(normalized_shape=[128], epsilon=1e-05)
      (mlp): MLP(
        (linear_pre): Sequential(
          (0): Linear(in_features=128, out_features=128, dtype=None)
          (1): GELU(approximate=False)
        )
        (linear_post): Linear(in_features=128, out_features=128, dtype=None)
        (linears): LayerList()
      )
    )
    (7): Transolver_block(
      (ln_1): LayerNorm(normalized_shape=[128], epsilon=1e-05)
      (Attn): Physics_Attention_Structured_Mesh_2D(
        (softmax): Softmax(axis=-1)
        (dropout): Dropout(p=0.0, axis=None, mode=upscale_in_train)
        (in_project_x): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (in_project_fx): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (in_project_slice): Linear(in_features=16, out_features=64, dtype=None)
        (to_q): Linear(in_features=16, out_features=16, dtype=None)
        (to_k): Linear(in_features=16, out_features=16, dtype=None)
        (to_v): Linear(in_features=16, out_features=16, dtype=None)
        (to_out): Sequential(
          (0): Linear(in_features=128, out_features=128, dtype=None)
          (1): Dropout(p=0.0, axis=None, mode=upscale_in_train)
        )
      )
      (ln_2): LayerNorm(normalized_shape=[128], epsilon=1e-05)
      (mlp): MLP(
        (linear_pre): Sequential(
          (0): Linear(in_features=128, out_features=128, dtype=None)
          (1): GELU(approximate=False)
        )
        (linear_post): Linear(in_features=128, out_features=128, dtype=None)
        (linears): LayerList()
      )
      (ln_3): LayerNorm(normalized_shape=[128], epsilon=1e-05)
      (mlp2): Linear(in_features=128, out_features=1, dtype=None)
    )
  )
)
Total Trainable Params: 2826945
W1029 22:19:58.109582 880429 multiply_fwd_func.cc:64] got different data type, run type protmotion automatically, this may cause data type been changed.
Epoch 0 Reg : 1.43652 Train loss : 0.26459
rel_err:0.23368224725962228
save model
Epoch 1 Reg : 1.12124 Train loss : 0.21533
rel_err:0.21260997986849714
Epoch 2 Reg : 0.96457 Train loss : 0.17851
rel_err:0.15204534753766424
Epoch 3 Reg : 0.78813 Train loss : 0.13761
rel_err:0.13461141191441406
Epoch 4 Reg : 0.74916 Train loss : 0.12966
rel_err:0.1280447244623275
Epoch 5 Reg : 0.70560 Train loss : 0.11957
rel_err:0.11630031197336693
Epoch 6 Reg : 0.68491 Train loss : 0.11570
rel_err:0.11106229566452047
Epoch 7 Reg : 0.63972 Train loss : 0.10635
rel_err:0.09699192479830698
Epoch 8 Reg : 0.62093 Train loss : 0.10010
rel_err:0.09095664625908985
Epoch 9 Reg : 0.59657 Train loss : 0.09560
rel_err:0.10150349195357256
Epoch 10 Reg : 0.57866 Train loss : 0.09235
rel_err:0.09015321042528868
Epoch 11 Reg : 0.56592 Train loss : 0.08932
rel_err:0.09966622573096526
Epoch 12 Reg : 0.56061 Train loss : 0.08632
rel_err:0.07579543569072211
Epoch 13 Reg : 0.54919 Train loss : 0.08416
rel_err:0.08393851539059581
Epoch 14 Reg : 0.54302 Train loss : 0.08216
rel_err:0.07563489932187493
Epoch 15 Reg : 0.52991 Train loss : 0.08039
rel_err:0.0768191805676456
Epoch 16 Reg : 0.52093 Train loss : 0.07717
rel_err:0.0814822475686859
Epoch 17 Reg : 0.50896 Train loss : 0.07400
rel_err:0.07207254401215171
Epoch 18 Reg : 0.50815 Train loss : 0.07312
rel_err:0.07532276944779981
Epoch 19 Reg : 0.49738 Train loss : 0.07224
rel_err:0.08270809991087948
Epoch 20 Reg : 0.49462 Train loss : 0.07036
rel_err:0.07623972186971324
Epoch 21 Reg : 0.48860 Train loss : 0.07121
rel_err:0.08170465538839423
Epoch 22 Reg : 0.48290 Train loss : 0.06832
rel_err:0.07017243686966534
Epoch 23 Reg : 0.46850 Train loss : 0.06703
rel_err:0.06483897254568721
Epoch 24 Reg : 0.46391 Train loss : 0.06522
rel_err:0.06513271921183139
Epoch 25 Reg : 0.45943 Train loss : 0.06694
rel_err:0.06223979098317853
Epoch 26 Reg : 0.44661 Train loss : 0.06426
rel_err:0.07251887001512147
Epoch 27 Reg : 0.42811 Train loss : 0.06181
rel_err:0.05612205899209055
Epoch 28 Reg : 0.41825 Train loss : 0.06130
rel_err:0.05889591744113641
Epoch 29 Reg : 0.40976 Train loss : 0.05886
rel_err:0.053387193991738024
Epoch 30 Reg : 0.40352 Train loss : 0.05759
rel_err:0.04938622321907041
Epoch 31 Reg : 0.39024 Train loss : 0.05578
rel_err:0.06326122941531682
Epoch 32 Reg : 0.39342 Train loss : 0.05732
rel_err:0.06105082395227794
Epoch 33 Reg : 0.37664 Train loss : 0.05330
rel_err:0.059111373675385985
Epoch 34 Reg : 0.37779 Train loss : 0.05450
rel_err:0.056700214174204844
Epoch 35 Reg : 0.36874 Train loss : 0.05271
rel_err:0.05167727157250809
Epoch 36 Reg : 0.35857 Train loss : 0.05152
rel_err:0.04991880476528541
Epoch 37 Reg : 0.35230 Train loss : 0.05016
rel_err:0.04524069929703517
Epoch 38 Reg : 0.35186 Train loss : 0.05139
rel_err:0.059537527675642646
Epoch 39 Reg : 0.34747 Train loss : 0.05077
rel_err:0.04295285049690078
Epoch 40 Reg : 0.32151 Train loss : 0.04633
rel_err:0.04454673940063952
Epoch 41 Reg : 0.32714 Train loss : 0.04822
rel_err:0.04455530879190733
Epoch 42 Reg : 0.31905 Train loss : 0.04653
rel_err:0.045082628695038124
Epoch 43 Reg : 0.31934 Train loss : 0.04666
rel_err:0.041012809333458924
Epoch 44 Reg : 0.30564 Train loss : 0.04502
rel_err:0.04575402752842516
Epoch 45 Reg : 0.30425 Train loss : 0.04459
rel_err:0.04444160515998763
Epoch 46 Reg : 0.29794 Train loss : 0.04394
rel_err:0.04126715753274334
Epoch 47 Reg : 0.29998 Train loss : 0.04444
rel_err:0.040681781265271715
Epoch 48 Reg : 0.28889 Train loss : 0.04173
rel_err:0.04648677242078827
Epoch 49 Reg : 0.29101 Train loss : 0.04354
rel_err:0.04797750436727501
Epoch 50 Reg : 0.27727 Train loss : 0.04072
rel_err:0.041946749370573404
Epoch 51 Reg : 0.26702 Train loss : 0.03907
rel_err:0.038356301162005085
Epoch 52 Reg : 0.26559 Train loss : 0.04119
rel_err:0.041877756458873795
Epoch 53 Reg : 0.26287 Train loss : 0.03974
rel_err:0.03540356743205767
Epoch 54 Reg : 0.25386 Train loss : 0.03966
rel_err:0.03258109835463814
Epoch 55 Reg : 0.25020 Train loss : 0.03814
rel_err:0.03872749463059803
Epoch 56 Reg : 0.24708 Train loss : 0.03827
rel_err:0.03225926042969137
Epoch 57 Reg : 0.24062 Train loss : 0.03587
rel_err:0.04305350274555587
Epoch 58 Reg : 0.23687 Train loss : 0.03617
rel_err:0.03776265265338871
Epoch 59 Reg : 0.23683 Train loss : 0.03644
rel_err:0.039575493655132035
Epoch 60 Reg : 0.23393 Train loss : 0.03540
rel_err:0.042810512717391704
Epoch 61 Reg : 0.23900 Train loss : 0.03768
rel_err:0.03179283791271089
Epoch 62 Reg : 0.22783 Train loss : 0.03511
rel_err:0.03159960115818071
Epoch 63 Reg : 0.21689 Train loss : 0.03354
rel_err:0.034347615684196746
Epoch 64 Reg : 0.22411 Train loss : 0.03587
rel_err:0.03141218145865701
Epoch 65 Reg : 0.23131 Train loss : 0.03697
rel_err:0.03256768254734624
Epoch 66 Reg : 0.21856 Train loss : 0.03375
rel_err:0.03365429618287593
Epoch 67 Reg : 0.21153 Train loss : 0.03310
rel_err:0.03580230612049045
Epoch 68 Reg : 0.20803 Train loss : 0.03355
rel_err:0.028993573955762086
Epoch 69 Reg : 0.21049 Train loss : 0.03278
rel_err:0.03214764807246628
Epoch 70 Reg : 0.20624 Train loss : 0.03202
rel_err:0.03252857953155607
Epoch 71 Reg : 0.20616 Train loss : 0.03244
rel_err:0.02500414024743342
Epoch 72 Reg : 0.19880 Train loss : 0.03153
rel_err:0.03583401753665621
Epoch 73 Reg : 0.20337 Train loss : 0.03311
rel_err:0.03195123682644615
Epoch 74 Reg : 0.20020 Train loss : 0.03270
rel_err:0.03644811001276719
Epoch 75 Reg : 0.20190 Train loss : 0.03226
rel_err:0.02968989134020235
Epoch 76 Reg : 0.19669 Train loss : 0.03079
rel_err:0.027165076706838934
Epoch 77 Reg : 0.19005 Train loss : 0.02988
rel_err:0.03469741326128392
Epoch 78 Reg : 0.19016 Train loss : 0.02956
rel_err:0.03331371374589459
Epoch 79 Reg : 0.19469 Train loss : 0.03150
rel_err:0.025593727439097866
Epoch 80 Reg : 0.19235 Train loss : 0.03041
rel_err:0.02825006102285083
Epoch 81 Reg : 0.18065 Train loss : 0.02753
rel_err:0.02741847893217194
Epoch 82 Reg : 0.19180 Train loss : 0.03028
rel_err:0.0283544561657997
Epoch 83 Reg : 0.18149 Train loss : 0.02851
rel_err:0.03835836157124421
Epoch 84 Reg : 0.18946 Train loss : 0.02917
rel_err:0.03088623367738118
Epoch 85 Reg : 0.18852 Train loss : 0.03021
rel_err:0.021002636969101717
Epoch 86 Reg : 0.17635 Train loss : 0.02770
rel_err:0.027341678425502457
Epoch 87 Reg : 0.17473 Train loss : 0.02795
rel_err:0.026530628763057406
Epoch 88 Reg : 0.16985 Train loss : 0.02681
rel_err:0.02892533435666208
Epoch 89 Reg : 0.18044 Train loss : 0.02791
rel_err:0.023983613624070213
Epoch 90 Reg : 0.17473 Train loss : 0.02703
rel_err:0.024686504796580282
Epoch 91 Reg : 0.17990 Train loss : 0.02858
rel_err:0.024268264007826015
Epoch 92 Reg : 0.18233 Train loss : 0.02932
rel_err:0.029168972767202983
Epoch 93 Reg : 0.16742 Train loss : 0.02701
rel_err:0.025201430498670116
Epoch 94 Reg : 0.16927 Train loss : 0.02651
rel_err:0.03226087374929604
Epoch 95 Reg : 0.16463 Train loss : 0.02493
rel_err:0.023666223928440533
Epoch 96 Reg : 0.16212 Train loss : 0.02512
rel_err:0.0317074413878464
Epoch 97 Reg : 0.17526 Train loss : 0.02725
rel_err:0.03053720953271589
Epoch 98 Reg : 0.16685 Train loss : 0.02649
rel_err:0.025263156706350882
Epoch 99 Reg : 0.16874 Train loss : 0.02621
rel_err:0.023956198920767512
Epoch 100 Reg : 0.17336 Train loss : 0.02874
rel_err:0.021564460101135143
save model
Epoch 101 Reg : 0.16813 Train loss : 0.02556
rel_err:0.023782308243612372
Epoch 102 Reg : 0.16476 Train loss : 0.02607
rel_err:0.026663059893233875
Epoch 103 Reg : 0.15991 Train loss : 0.02497
rel_err:0.0321697854312446
Epoch 104 Reg : 0.16840 Train loss : 0.02605
rel_err:0.03088920307066407
Epoch 105 Reg : 0.16434 Train loss : 0.02540
rel_err:0.023397061706870007
Epoch 106 Reg : 0.16471 Train loss : 0.02586
rel_err:0.0237814041555975
Epoch 107 Reg : 0.16752 Train loss : 0.02656
rel_err:0.02244392863132232
Epoch 108 Reg : 0.15195 Train loss : 0.02305
rel_err:0.02151082915171881
Epoch 109 Reg : 0.15963 Train loss : 0.02439
rel_err:0.023084787161908163
Epoch 110 Reg : 0.16209 Train loss : 0.02517
rel_err:0.02793285161293951
Epoch 111 Reg : 0.15822 Train loss : 0.02447
rel_err:0.02381753819097897
Epoch 112 Reg : 0.15677 Train loss : 0.02420
rel_err:0.024819155228115414
Epoch 113 Reg : 0.16132 Train loss : 0.02501
rel_err:0.022281998816753093
Epoch 114 Reg : 0.15143 Train loss : 0.02327
rel_err:0.01790915482531319
Epoch 115 Reg : 0.15027 Train loss : 0.02307
rel_err:0.028329523141693666
Epoch 116 Reg : 0.16074 Train loss : 0.02526
rel_err:0.020373928059958867
Epoch 117 Reg : 0.14324 Train loss : 0.02184
rel_err:0.02437488769426177
Epoch 118 Reg : 0.15243 Train loss : 0.02306
rel_err:0.020079913881419702
Epoch 119 Reg : 0.14822 Train loss : 0.02318
rel_err:0.024344788213168895
Epoch 120 Reg : 0.14602 Train loss : 0.02188
rel_err:0.02096991126015586
Epoch 121 Reg : 0.14758 Train loss : 0.02260
rel_err:0.02490362827755344
Epoch 122 Reg : 0.15279 Train loss : 0.02313
rel_err:0.023666515845148915
Epoch 123 Reg : 0.15226 Train loss : 0.02347
rel_err:0.023112823942591176
Epoch 124 Reg : 0.13625 Train loss : 0.02053
rel_err:0.01815082271486013
Epoch 125 Reg : 0.14736 Train loss : 0.02258
rel_err:0.020294471359250287
Epoch 126 Reg : 0.13975 Train loss : 0.02113
rel_err:0.018879565167668862
Epoch 127 Reg : 0.13811 Train loss : 0.02062
rel_err:0.02036655671732917
Epoch 128 Reg : 0.14604 Train loss : 0.02270
rel_err:0.03378355854766726
Epoch 129 Reg : 0.14646 Train loss : 0.02217
rel_err:0.0227884106182573
Epoch 130 Reg : 0.13286 Train loss : 0.01915
rel_err:0.02812566211115556
Epoch 131 Reg : 0.14153 Train loss : 0.02166
rel_err:0.021391229173858176
Epoch 132 Reg : 0.14562 Train loss : 0.02155
rel_err:0.036226513129193165
Epoch 133 Reg : 0.13732 Train loss : 0.02044
rel_err:0.016379491341752036
Epoch 134 Reg : 0.13475 Train loss : 0.01999
rel_err:0.018442491546238546
Epoch 135 Reg : 0.14773 Train loss : 0.02192
rel_err:0.0184321671195062
Epoch 136 Reg : 0.13815 Train loss : 0.02025
rel_err:0.022719615893066834
Epoch 137 Reg : 0.13264 Train loss : 0.01914
rel_err:0.025498841258524783
Epoch 138 Reg : 0.13041 Train loss : 0.01889
rel_err:0.019129382625524497
Epoch 139 Reg : 0.13234 Train loss : 0.01992
rel_err:0.018124629861514353
Epoch 140 Reg : 0.13221 Train loss : 0.01950
rel_err:0.015902669637366938
Epoch 141 Reg : 0.12875 Train loss : 0.01951
rel_err:0.017759485307064646
Epoch 142 Reg : 0.12674 Train loss : 0.01856
rel_err:0.017920758991957948
Epoch 143 Reg : 0.12824 Train loss : 0.01853
rel_err:0.021397296254226466
Epoch 144 Reg : 0.13533 Train loss : 0.01982
rel_err:0.02371950910331809
Epoch 145 Reg : 0.13519 Train loss : 0.02025
rel_err:0.021064917395231197
Epoch 146 Reg : 0.12968 Train loss : 0.01935
rel_err:0.020003727277785016
Epoch 147 Reg : 0.12443 Train loss : 0.01797
rel_err:0.01801878009536953
Epoch 148 Reg : 0.13850 Train loss : 0.02085
rel_err:0.017371307521117624
Epoch 149 Reg : 0.12757 Train loss : 0.01877
rel_err:0.024645268314626146
Epoch 150 Reg : 0.13633 Train loss : 0.01971
rel_err:0.01913863253711042
Epoch 151 Reg : 0.12533 Train loss : 0.01808
rel_err:0.016808363976478828
Epoch 152 Reg : 0.12033 Train loss : 0.01729
rel_err:0.0192537661350978
Epoch 153 Reg : 0.12697 Train loss : 0.01865
rel_err:0.02189156959537243
Epoch 154 Reg : 0.12257 Train loss : 0.01778
rel_err:0.015262868618088477
Epoch 155 Reg : 0.12582 Train loss : 0.01814
rel_err:0.020541654411244198
Epoch 156 Reg : 0.12250 Train loss : 0.01801
rel_err:0.02621754267893514
Epoch 157 Reg : 0.11909 Train loss : 0.01722
rel_err:0.02354660854754096
Epoch 158 Reg : 0.11779 Train loss : 0.01712
rel_err:0.015490404294207512
Epoch 159 Reg : 0.12034 Train loss : 0.01736
rel_err:0.01593777229702582
Epoch 160 Reg : 0.11401 Train loss : 0.01674
rel_err:0.01465045648104385
Epoch 161 Reg : 0.11647 Train loss : 0.01726
rel_err:0.019548593080251624
Epoch 162 Reg : 0.11874 Train loss : 0.01708
rel_err:0.016606260806947146
Epoch 163 Reg : 0.12059 Train loss : 0.01777
rel_err:0.018698994029319266
Epoch 164 Reg : 0.11335 Train loss : 0.01586
rel_err:0.021550025679367448
Epoch 165 Reg : 0.11492 Train loss : 0.01676
rel_err:0.015078562786630157
Epoch 166 Reg : 0.11660 Train loss : 0.01643
rel_err:0.014405084246198565
Epoch 167 Reg : 0.11128 Train loss : 0.01549
rel_err:0.01586409160934454
Epoch 168 Reg : 0.11849 Train loss : 0.01724
rel_err:0.01658614071993191
Epoch 169 Reg : 0.10758 Train loss : 0.01515
rel_err:0.017797145023811058
Epoch 170 Reg : 0.11171 Train loss : 0.01619
rel_err:0.018873974682653935
Epoch 171 Reg : 0.10969 Train loss : 0.01563
rel_err:0.02139836676740478
Epoch 172 Reg : 0.12461 Train loss : 0.01841
rel_err:0.015342386278889666
Epoch 173 Reg : 0.11627 Train loss : 0.01723
rel_err:0.026098081048742682
Epoch 174 Reg : 0.11418 Train loss : 0.01601
rel_err:0.016515026799648627
Epoch 175 Reg : 0.10346 Train loss : 0.01463
rel_err:0.021311597884977326
Epoch 176 Reg : 0.11244 Train loss : 0.01554
rel_err:0.016054252619817272
Epoch 177 Reg : 0.11002 Train loss : 0.01509
rel_err:0.013204809380395676
Epoch 178 Reg : 0.10331 Train loss : 0.01481
rel_err:0.012857951737480054
Epoch 179 Reg : 0.11365 Train loss : 0.01672
rel_err:0.015036477075713494
Epoch 180 Reg : 0.10463 Train loss : 0.01483
rel_err:0.01534067644648617
Epoch 181 Reg : 0.10924 Train loss : 0.01527
rel_err:0.01687244574221143
Epoch 182 Reg : 0.10371 Train loss : 0.01413
rel_err:0.014920807616320132
Epoch 183 Reg : 0.10933 Train loss : 0.01571
rel_err:0.019315064771763136
Epoch 184 Reg : 0.10296 Train loss : 0.01482
rel_err:0.016163802112104136
Epoch 185 Reg : 0.10032 Train loss : 0.01363
rel_err:0.016088323955591982
Epoch 186 Reg : 0.10584 Train loss : 0.01455
rel_err:0.012590103335312557
Epoch 187 Reg : 0.10555 Train loss : 0.01515
rel_err:0.017187400947506995
Epoch 188 Reg : 0.10513 Train loss : 0.01452
rel_err:0.014090029204668519
Epoch 189 Reg : 0.10333 Train loss : 0.01450
rel_err:0.014972596803331724
Epoch 190 Reg : 0.10004 Train loss : 0.01363
rel_err:0.018416861849696473
Epoch 191 Reg : 0.10137 Train loss : 0.01381
rel_err:0.018531343519719568
Epoch 192 Reg : 0.10174 Train loss : 0.01383
rel_err:0.016266360833951075
Epoch 193 Reg : 0.09935 Train loss : 0.01334
rel_err:0.011176624010676268
Epoch 194 Reg : 0.09922 Train loss : 0.01364
rel_err:0.017346231273493065
Epoch 195 Reg : 0.10025 Train loss : 0.01382
rel_err:0.015074272202351474
Epoch 196 Reg : 0.09494 Train loss : 0.01298
rel_err:0.015672111206052334
Epoch 197 Reg : 0.10198 Train loss : 0.01419
rel_err:0.011967628694635326
Epoch 198 Reg : 0.09856 Train loss : 0.01344
rel_err:0.014884028950819533
Epoch 199 Reg : 0.09553 Train loss : 0.01301
rel_err:0.01505068218342514
Epoch 200 Reg : 0.10264 Train loss : 0.01427
rel_err:0.019004129781484736
save model
Epoch 201 Reg : 0.10467 Train loss : 0.01453
rel_err:0.013310338048667747
Epoch 202 Reg : 0.09327 Train loss : 0.01204
rel_err:0.014437502315423772
Epoch 203 Reg : 0.08846 Train loss : 0.01111
rel_err:0.01439293703897419
Epoch 204 Reg : 0.09742 Train loss : 0.01357
rel_err:0.012913333663541037
Epoch 205 Reg : 0.09533 Train loss : 0.01297
rel_err:0.014463923046952726
Epoch 206 Reg : 0.09856 Train loss : 0.01359
rel_err:0.013686558500012921
Epoch 207 Reg : 0.09734 Train loss : 0.01287
rel_err:0.017803359318515247
Epoch 208 Reg : 0.09762 Train loss : 0.01326
rel_err:0.018597756039561125
Epoch 209 Reg : 0.09497 Train loss : 0.01242
rel_err:0.013197380212690069
Epoch 210 Reg : 0.09396 Train loss : 0.01253
rel_err:0.013420232383572338
Epoch 211 Reg : 0.09733 Train loss : 0.01282
rel_err:0.014548125145798896
Epoch 212 Reg : 0.09493 Train loss : 0.01257
rel_err:0.01302043281601734
Epoch 213 Reg : 0.09094 Train loss : 0.01157
rel_err:0.013906528730104135
Epoch 214 Reg : 0.09535 Train loss : 0.01248
rel_err:0.011253418767701601
Epoch 215 Reg : 0.09033 Train loss : 0.01186
rel_err:0.009860334316911527
Epoch 216 Reg : 0.09778 Train loss : 0.01335
rel_err:0.012972265011584126
Epoch 217 Reg : 0.09237 Train loss : 0.01191
rel_err:0.015976630741692102
Epoch 218 Reg : 0.09450 Train loss : 0.01256
rel_err:0.014522025460483505
Epoch 219 Reg : 0.09399 Train loss : 0.01236
rel_err:0.01618874956324398
Epoch 220 Reg : 0.09265 Train loss : 0.01230
rel_err:0.01331450358967151
Epoch 221 Reg : 0.08649 Train loss : 0.01088
rel_err:0.011289897094895134
Epoch 222 Reg : 0.08761 Train loss : 0.01099
rel_err:0.010328640758509028
Epoch 223 Reg : 0.08860 Train loss : 0.01122
rel_err:0.00988952785551273
Epoch 224 Reg : 0.09110 Train loss : 0.01190
rel_err:0.012387668583136146
Epoch 225 Reg : 0.09693 Train loss : 0.01278
rel_err:0.009268964162422476
Epoch 226 Reg : 0.09010 Train loss : 0.01184
rel_err:0.012569603902194608
Epoch 227 Reg : 0.09178 Train loss : 0.01179
rel_err:0.014009564188773466
Epoch 228 Reg : 0.08873 Train loss : 0.01135
rel_err:0.010911670426946896
Epoch 229 Reg : 0.08783 Train loss : 0.01124
rel_err:0.014355391364035386
Epoch 230 Reg : 0.09113 Train loss : 0.01236
rel_err:0.010864655021664804
Epoch 231 Reg : 0.09315 Train loss : 0.01229
rel_err:0.011682042564879515
Epoch 232 Reg : 0.08884 Train loss : 0.01153
rel_err:0.014389109013375057
Epoch 233 Reg : 0.08628 Train loss : 0.01083
rel_err:0.012414653722312792
Epoch 234 Reg : 0.08925 Train loss : 0.01102
rel_err:0.011034626754969997
Epoch 235 Reg : 0.08431 Train loss : 0.01016
rel_err:0.009738215312982057
Epoch 236 Reg : 0.08841 Train loss : 0.01124
rel_err:0.012581046866879346
Epoch 237 Reg : 0.09331 Train loss : 0.01240
rel_err:0.011190896697908244
Epoch 238 Reg : 0.08732 Train loss : 0.01090
rel_err:0.011683021742408699
Epoch 239 Reg : 0.08759 Train loss : 0.01104
rel_err:0.008696518475892152
Epoch 240 Reg : 0.08907 Train loss : 0.01176
rel_err:0.010161069848641846
Epoch 241 Reg : 0.08971 Train loss : 0.01157
rel_err:0.01240043578813549
Epoch 242 Reg : 0.08818 Train loss : 0.01091
rel_err:0.009710371891206625
Epoch 243 Reg : 0.08601 Train loss : 0.01031
rel_err:0.015414620813457552
Epoch 244 Reg : 0.08272 Train loss : 0.00996
rel_err:0.011210518142195123
Epoch 245 Reg : 0.08496 Train loss : 0.01049
rel_err:0.012748071707844612
Epoch 246 Reg : 0.08210 Train loss : 0.00949
rel_err:0.010799352800411588
Epoch 247 Reg : 0.08567 Train loss : 0.01084
rel_err:0.011857980974255031
Epoch 248 Reg : 0.08409 Train loss : 0.01032
rel_err:0.009933818616517369
Epoch 249 Reg : 0.08503 Train loss : 0.01117
rel_err:0.012226063465241608
Epoch 250 Reg : 0.08262 Train loss : 0.00968
rel_err:0.011230125974942424
Epoch 251 Reg : 0.08324 Train loss : 0.01045
rel_err:0.012501662337902572
Epoch 252 Reg : 0.08644 Train loss : 0.01106
rel_err:0.014177620727613588
Epoch 253 Reg : 0.08484 Train loss : 0.01028
rel_err:0.010756961372825684
Epoch 254 Reg : 0.08181 Train loss : 0.00986
rel_err:0.009797308836164358
Epoch 255 Reg : 0.08259 Train loss : 0.00977
rel_err:0.010856471867480032
Epoch 256 Reg : 0.09185 Train loss : 0.01206
rel_err:0.010982573619771636
Epoch 257 Reg : 0.08680 Train loss : 0.01043
rel_err:0.010774235493791586
Epoch 258 Reg : 0.08161 Train loss : 0.00969
rel_err:0.009562422220378442
Epoch 259 Reg : 0.08029 Train loss : 0.00950
rel_err:0.013009234383182808
Epoch 260 Reg : 0.08410 Train loss : 0.01035
rel_err:0.012990194633627357
Epoch 261 Reg : 0.08007 Train loss : 0.00929
rel_err:0.0104840566305733
Epoch 262 Reg : 0.08006 Train loss : 0.00946
rel_err:0.009530488397271995
Epoch 263 Reg : 0.08422 Train loss : 0.01037
rel_err:0.010303912316523788
Epoch 264 Reg : 0.08039 Train loss : 0.00920
rel_err:0.011848640566902897
Epoch 265 Reg : 0.08205 Train loss : 0.01000
rel_err:0.014023157830490296
Epoch 266 Reg : 0.08026 Train loss : 0.00931
rel_err:0.009619140445267826
Epoch 267 Reg : 0.07945 Train loss : 0.00939
rel_err:0.009798218994223675
Epoch 268 Reg : 0.07696 Train loss : 0.00899
rel_err:0.012118773119354588
Epoch 269 Reg : 0.07724 Train loss : 0.00862
rel_err:0.009806492335283615
Epoch 270 Reg : 0.08091 Train loss : 0.00949
rel_err:0.010972763162966487
Epoch 271 Reg : 0.08393 Train loss : 0.01018
rel_err:0.010227152741525131
Epoch 272 Reg : 0.07954 Train loss : 0.00954
rel_err:0.010672701969303405
Epoch 273 Reg : 0.08337 Train loss : 0.01006
rel_err:0.010055389845723475
Epoch 274 Reg : 0.08007 Train loss : 0.00932
rel_err:0.012702927784529645
Epoch 275 Reg : 0.07863 Train loss : 0.00883
rel_err:0.009449738763052795
Epoch 276 Reg : 0.07843 Train loss : 0.00901
rel_err:0.01138420881719611
Epoch 277 Reg : 0.07927 Train loss : 0.00903
rel_err:0.010007666857942634
Epoch 278 Reg : 0.08075 Train loss : 0.00931
rel_err:0.009389078162904758
Epoch 279 Reg : 0.07837 Train loss : 0.00909
rel_err:0.010595074761919352
Epoch 280 Reg : 0.07822 Train loss : 0.00877
rel_err:0.008137027242332687
Epoch 281 Reg : 0.07801 Train loss : 0.00854
rel_err:0.012559545688945345
Epoch 282 Reg : 0.07825 Train loss : 0.00900
rel_err:0.01051602100726149
Epoch 283 Reg : 0.07851 Train loss : 0.00890
rel_err:0.009116608750462447
Epoch 284 Reg : 0.08097 Train loss : 0.00925
rel_err:0.009404568866635366
Epoch 285 Reg : 0.07695 Train loss : 0.00886
rel_err:0.009978698679765023
Epoch 286 Reg : 0.07788 Train loss : 0.00906
rel_err:0.00903815499477595
Epoch 287 Reg : 0.07658 Train loss : 0.00849
rel_err:0.0089987517093898
Epoch 288 Reg : 0.07578 Train loss : 0.00868
rel_err:0.010539231226458856
Epoch 289 Reg : 0.07928 Train loss : 0.00933
rel_err:0.010897894719087248
Epoch 290 Reg : 0.07936 Train loss : 0.00892
rel_err:0.008779673597459282
Epoch 291 Reg : 0.07757 Train loss : 0.00850
rel_err:0.01035498835917524
Epoch 292 Reg : 0.07665 Train loss : 0.00834
rel_err:0.008809034626362155
Epoch 293 Reg : 0.07356 Train loss : 0.00761
rel_err:0.011083064620651038
Epoch 294 Reg : 0.07545 Train loss : 0.00826
rel_err:0.011379208229462558
Epoch 295 Reg : 0.07597 Train loss : 0.00862
rel_err:0.008569777068308977
Epoch 296 Reg : 0.07395 Train loss : 0.00765
rel_err:0.008541739730619963
Epoch 297 Reg : 0.07460 Train loss : 0.00792
rel_err:0.010572979853259728
Epoch 298 Reg : 0.07325 Train loss : 0.00773
rel_err:0.008148899890161022
Epoch 299 Reg : 0.07085 Train loss : 0.00697
rel_err:0.009733033833139632
Epoch 300 Reg : 0.07530 Train loss : 0.00821
rel_err:0.007831629588730342
save model
Epoch 301 Reg : 0.07545 Train loss : 0.00848
rel_err:0.009169327102821654
Epoch 302 Reg : 0.07271 Train loss : 0.00767
rel_err:0.008128135106688883
Epoch 303 Reg : 0.07409 Train loss : 0.00775
rel_err:0.008677350159652056
Epoch 304 Reg : 0.07422 Train loss : 0.00774
rel_err:0.007612592946717302
Epoch 305 Reg : 0.07654 Train loss : 0.00842
rel_err:0.011872541727799472
Epoch 306 Reg : 0.07570 Train loss : 0.00848
rel_err:0.009775034822025255
Epoch 307 Reg : 0.07432 Train loss : 0.00804
rel_err:0.00769449678997141
Epoch 308 Reg : 0.07187 Train loss : 0.00735
rel_err:0.00868492086563086
Epoch 309 Reg : 0.07295 Train loss : 0.00755
rel_err:0.007430836292078987
Epoch 310 Reg : 0.07204 Train loss : 0.00736
rel_err:0.011072208716612882
Epoch 311 Reg : 0.07233 Train loss : 0.00723
rel_err:0.008125849078811807
Epoch 312 Reg : 0.07161 Train loss : 0.00749
rel_err:0.008585915804050421
Epoch 313 Reg : 0.07391 Train loss : 0.00770
rel_err:0.009073860170612014
Epoch 314 Reg : 0.07276 Train loss : 0.00776
rel_err:0.007153605150422183
Epoch 315 Reg : 0.07363 Train loss : 0.00774
rel_err:0.008907721663026924
Epoch 316 Reg : 0.07044 Train loss : 0.00693
rel_err:0.007431787764117273
Epoch 317 Reg : 0.07448 Train loss : 0.00782
rel_err:0.009048835663636083
Epoch 318 Reg : 0.07384 Train loss : 0.00799
rel_err:0.009832150169239546
Epoch 319 Reg : 0.07208 Train loss : 0.00734
rel_err:0.008698396291773953
Epoch 320 Reg : 0.07168 Train loss : 0.00739
rel_err:0.00729117557656192
Epoch 321 Reg : 0.07451 Train loss : 0.00792
rel_err:0.008918335912786764
Epoch 322 Reg : 0.07406 Train loss : 0.00781
rel_err:0.010028718317694457
Epoch 323 Reg : 0.06998 Train loss : 0.00686
rel_err:0.0070336058493196
Epoch 324 Reg : 0.07102 Train loss : 0.00705
rel_err:0.0078103315723313145
Epoch 325 Reg : 0.07133 Train loss : 0.00710
rel_err:0.00841413246697688
Epoch 326 Reg : 0.07013 Train loss : 0.00688
rel_err:0.007988450570216729
Epoch 327 Reg : 0.07227 Train loss : 0.00737
rel_err:0.009049966894584344
Epoch 328 Reg : 0.06980 Train loss : 0.00671
rel_err:0.007536689256455045
Epoch 329 Reg : 0.06909 Train loss : 0.00645
rel_err:0.00840536928707405
Epoch 330 Reg : 0.06933 Train loss : 0.00644
rel_err:0.010098926391238406
Epoch 331 Reg : 0.06798 Train loss : 0.00603
rel_err:0.008911466780208748
Epoch 332 Reg : 0.06860 Train loss : 0.00617
rel_err:0.010122586466173639
Epoch 333 Reg : 0.07262 Train loss : 0.00735
rel_err:0.00819214835321453
Epoch 334 Reg : 0.06933 Train loss : 0.00664
rel_err:0.00808700093371229
Epoch 335 Reg : 0.07093 Train loss : 0.00688
rel_err:0.009218774876155543
Epoch 336 Reg : 0.06855 Train loss : 0.00626
rel_err:0.0069802190207130495
Epoch 337 Reg : 0.06806 Train loss : 0.00613
rel_err:0.008911861554102504
Epoch 338 Reg : 0.06826 Train loss : 0.00640
rel_err:0.010731982341966395
Epoch 339 Reg : 0.06834 Train loss : 0.00635
rel_err:0.008865579785074408
Epoch 340 Reg : 0.06943 Train loss : 0.00665
rel_err:0.00806457292895315
Epoch 341 Reg : 0.06771 Train loss : 0.00623
rel_err:0.010689162250089288
Epoch 342 Reg : 0.07074 Train loss : 0.00697
rel_err:0.007094615619589941
Epoch 343 Reg : 0.06816 Train loss : 0.00619
rel_err:0.007874693357513965
Epoch 344 Reg : 0.06652 Train loss : 0.00564
rel_err:0.0077531591631765625
Epoch 345 Reg : 0.06835 Train loss : 0.00637
rel_err:0.006736203843482038
Epoch 346 Reg : 0.06817 Train loss : 0.00649
rel_err:0.006772998416943999
Epoch 347 Reg : 0.06702 Train loss : 0.00585
rel_err:0.008849692472761475
Epoch 348 Reg : 0.06677 Train loss : 0.00569
rel_err:0.007176402914592793
Epoch 349 Reg : 0.06751 Train loss : 0.00634
rel_err:0.006808731509819239
Epoch 350 Reg : 0.06581 Train loss : 0.00544
rel_err:0.00786147476160225
Epoch 351 Reg : 0.06787 Train loss : 0.00613
rel_err:0.00804659801224144
Epoch 352 Reg : 0.06693 Train loss : 0.00576
rel_err:0.006912960974170895
Epoch 353 Reg : 0.06591 Train loss : 0.00566
rel_err:0.007795003946561928
Epoch 354 Reg : 0.06572 Train loss : 0.00551
rel_err:0.007492188225242565
Epoch 355 Reg : 0.06658 Train loss : 0.00583
rel_err:0.007307706416354284
Epoch 356 Reg : 0.06595 Train loss : 0.00562
rel_err:0.0076203761239597686
Epoch 357 Reg : 0.06704 Train loss : 0.00590
rel_err:0.00729437678201006
Epoch 358 Reg : 0.06506 Train loss : 0.00525
rel_err:0.009051652779017412
Epoch 359 Reg : 0.06685 Train loss : 0.00588
rel_err:0.008727240594621315
Epoch 360 Reg : 0.06677 Train loss : 0.00598
rel_err:0.00794015345848766
Epoch 361 Reg : 0.06618 Train loss : 0.00578
rel_err:0.007593547882659936
Epoch 362 Reg : 0.06622 Train loss : 0.00570
rel_err:0.006756415367859589
Epoch 363 Reg : 0.06480 Train loss : 0.00513
rel_err:0.006931204069407092
Epoch 364 Reg : 0.06486 Train loss : 0.00513
rel_err:0.006714176179632453
Epoch 365 Reg : 0.06526 Train loss : 0.00534
rel_err:0.009984581814620237
Epoch 366 Reg : 0.06669 Train loss : 0.00592
rel_err:0.008422177677824862
Epoch 367 Reg : 0.06545 Train loss : 0.00548
rel_err:0.007687280104799395
Epoch 368 Reg : 0.06529 Train loss : 0.00533
rel_err:0.006299471466132166
Epoch 369 Reg : 0.06529 Train loss : 0.00528
rel_err:0.007495926499180706
Epoch 370 Reg : 0.06441 Train loss : 0.00496
rel_err:0.0065049120928849504
Epoch 371 Reg : 0.06539 Train loss : 0.00558
rel_err:0.007063324682957098
Epoch 372 Reg : 0.06354 Train loss : 0.00475
rel_err:0.006848524444802276
Epoch 373 Reg : 0.06447 Train loss : 0.00520
rel_err:0.0065101652744053665
Epoch 374 Reg : 0.06517 Train loss : 0.00538
rel_err:0.00711223030560957
Epoch 375 Reg : 0.06357 Train loss : 0.00471
rel_err:0.006941275065344383
Epoch 376 Reg : 0.06341 Train loss : 0.00476
rel_err:0.008202771593248394
Epoch 377 Reg : 0.06325 Train loss : 0.00472
rel_err:0.00663299507275135
Epoch 378 Reg : 0.06395 Train loss : 0.00507
rel_err:0.007150009958060656
Epoch 379 Reg : 0.06467 Train loss : 0.00530
rel_err:0.007016622382473036
Epoch 380 Reg : 0.06402 Train loss : 0.00490
rel_err:0.007273810093723786
Epoch 381 Reg : 0.06332 Train loss : 0.00480
rel_err:0.007181466826546107
Epoch 382 Reg : 0.06352 Train loss : 0.00488
rel_err:0.007572846752986819
Epoch 383 Reg : 0.06412 Train loss : 0.00498
rel_err:0.006098722641212859
Epoch 384 Reg : 0.06369 Train loss : 0.00484
rel_err:0.007687716199762782
Epoch 385 Reg : 0.06392 Train loss : 0.00495
rel_err:0.006775853973639433
Epoch 386 Reg : 0.06426 Train loss : 0.00499
rel_err:0.006705131394130195
Epoch 387 Reg : 0.06316 Train loss : 0.00482
rel_err:0.007208564651977052
Epoch 388 Reg : 0.06310 Train loss : 0.00472
rel_err:0.006486212100994166
Epoch 389 Reg : 0.06283 Train loss : 0.00466
rel_err:0.008212809395154846
Epoch 390 Reg : 0.06396 Train loss : 0.00528
rel_err:0.006833954859418439
Epoch 391 Reg : 0.06250 Train loss : 0.00465
rel_err:0.006433733019830871
Epoch 392 Reg : 0.06306 Train loss : 0.00458
rel_err:0.0061765316892812994
Epoch 393 Reg : 0.06314 Train loss : 0.00477
rel_err:0.00653206948052081
Epoch 394 Reg : 0.06233 Train loss : 0.00446
rel_err:0.006972743945683175
Epoch 395 Reg : 0.06211 Train loss : 0.00434
rel_err:0.007924709799663414
Epoch 396 Reg : 0.06272 Train loss : 0.00455
rel_err:0.006234697104381363
Epoch 397 Reg : 0.06287 Train loss : 0.00460
rel_err:0.006315903563368463
Epoch 398 Reg : 0.06214 Train loss : 0.00434
rel_err:0.0061588672176680305
Epoch 399 Reg : 0.06121 Train loss : 0.00397
rel_err:0.006613790993915681
Epoch 400 Reg : 0.06195 Train loss : 0.00427
rel_err:0.006239615756836473
save model
Epoch 401 Reg : 0.06198 Train loss : 0.00438
rel_err:0.006511623240944866
Epoch 402 Reg : 0.06247 Train loss : 0.00453
rel_err:0.006952308314548148
Epoch 403 Reg : 0.06191 Train loss : 0.00419
rel_err:0.006346050388800279
Epoch 404 Reg : 0.06132 Train loss : 0.00404
rel_err:0.006211258816224475
Epoch 405 Reg : 0.06179 Train loss : 0.00415
rel_err:0.006608099900754692
Epoch 406 Reg : 0.06186 Train loss : 0.00419
rel_err:0.006130295844227533
Epoch 407 Reg : 0.06121 Train loss : 0.00395
rel_err:0.006373320343713574
Epoch 408 Reg : 0.06178 Train loss : 0.00434
rel_err:0.0067599420405145385
Epoch 409 Reg : 0.06164 Train loss : 0.00413
rel_err:0.006032655434746323
Epoch 410 Reg : 0.06111 Train loss : 0.00400
rel_err:0.006067294236122653
Epoch 411 Reg : 0.06133 Train loss : 0.00407
rel_err:0.00640627391577557
Epoch 412 Reg : 0.06146 Train loss : 0.00407
rel_err:0.006539425704665852
Epoch 413 Reg : 0.06176 Train loss : 0.00428
rel_err:0.006133551938262682
Epoch 414 Reg : 0.06109 Train loss : 0.00393
rel_err:0.006157934870742211
Epoch 415 Reg : 0.06097 Train loss : 0.00391
rel_err:0.006192544324116558
Epoch 416 Reg : 0.06135 Train loss : 0.00418
rel_err:0.006395347588829338
Epoch 417 Reg : 0.06105 Train loss : 0.00403
rel_err:0.006353267851434759
Epoch 418 Reg : 0.06093 Train loss : 0.00396
rel_err:0.0062606579829137966
Epoch 419 Reg : 0.06096 Train loss : 0.00395
rel_err:0.0062090686962823025
Epoch 420 Reg : 0.06075 Train loss : 0.00389
rel_err:0.006181056149657282
Epoch 421 Reg : 0.06054 Train loss : 0.00379
rel_err:0.005955667334271962
Epoch 422 Reg : 0.06056 Train loss : 0.00374
rel_err:0.006172403188280905
Epoch 423 Reg : 0.06071 Train loss : 0.00398
rel_err:0.006091167578590472
Epoch 424 Reg : 0.06051 Train loss : 0.00384
rel_err:0.006056659948136704
Epoch 425 Reg : 0.06066 Train loss : 0.00382
rel_err:0.00629667547562058
Epoch 426 Reg : 0.06012 Train loss : 0.00364
rel_err:0.00625357636268576
Epoch 427 Reg : 0.06043 Train loss : 0.00384
rel_err:0.006569742576059277
Epoch 428 Reg : 0.06018 Train loss : 0.00363
rel_err:0.0063958439736052815
Epoch 429 Reg : 0.06024 Train loss : 0.00370
rel_err:0.005901592337037362
Epoch 430 Reg : 0.06003 Train loss : 0.00367
rel_err:0.0059777503358185114
Epoch 431 Reg : 0.06019 Train loss : 0.00373
rel_err:0.007062605680187046
Epoch 432 Reg : 0.06019 Train loss : 0.00366
rel_err:0.005973735391095762
Epoch 433 Reg : 0.06000 Train loss : 0.00363
rel_err:0.006083048378746317
Epoch 434 Reg : 0.06007 Train loss : 0.00361
rel_err:0.006514798608703818
Epoch 435 Reg : 0.06026 Train loss : 0.00371
rel_err:0.0058662523013769015
Epoch 436 Reg : 0.05966 Train loss : 0.00342
rel_err:0.006083071025786162
Epoch 437 Reg : 0.05996 Train loss : 0.00356
rel_err:0.005925631779055512
Epoch 438 Reg : 0.05976 Train loss : 0.00351
rel_err:0.0058367925093633
Epoch 439 Reg : 0.05977 Train loss : 0.00355
rel_err:0.0061703619719804936
Epoch 440 Reg : 0.05982 Train loss : 0.00348
rel_err:0.0059054170407790065
Epoch 441 Reg : 0.05958 Train loss : 0.00338
rel_err:0.005791797844378728
Epoch 442 Reg : 0.05964 Train loss : 0.00339
rel_err:0.006190180068731446
Epoch 443 Reg : 0.05989 Train loss : 0.00360
rel_err:0.005966013720946351
Epoch 444 Reg : 0.05955 Train loss : 0.00344
rel_err:0.005885041744468791
Epoch 445 Reg : 0.05933 Train loss : 0.00333
rel_err:0.0061630027294271895
Epoch 446 Reg : 0.05936 Train loss : 0.00330
rel_err:0.005962109498931647
Epoch 447 Reg : 0.05952 Train loss : 0.00339
rel_err:0.005895653546947862
Epoch 448 Reg : 0.05933 Train loss : 0.00327
rel_err:0.0058602359550403715
Epoch 449 Reg : 0.05953 Train loss : 0.00343
rel_err:0.005985869677075361
Epoch 450 Reg : 0.05944 Train loss : 0.00341
rel_err:0.005793978305096312
Epoch 451 Reg : 0.05911 Train loss : 0.00324
rel_err:0.0062001732085809535
Epoch 452 Reg : 0.05932 Train loss : 0.00333
rel_err:0.006139169952658813
Epoch 453 Reg : 0.05911 Train loss : 0.00323
rel_err:0.005833126767555184
Epoch 454 Reg : 0.05913 Train loss : 0.00327
rel_err:0.006205332226369618
Epoch 455 Reg : 0.05935 Train loss : 0.00338
rel_err:0.005904517676469306
Epoch 456 Reg : 0.05917 Train loss : 0.00333
rel_err:0.00586046762865598
Epoch 457 Reg : 0.05904 Train loss : 0.00326
rel_err:0.00577483069759824
Epoch 458 Reg : 0.05905 Train loss : 0.00323
rel_err:0.005880582878440343
Epoch 459 Reg : 0.05901 Train loss : 0.00319
rel_err:0.005952249014505869
Epoch 460 Reg : 0.05900 Train loss : 0.00324
rel_err:0.00586569651849324
Epoch 461 Reg : 0.05907 Train loss : 0.00329
rel_err:0.005735109293781931
Epoch 462 Reg : 0.05881 Train loss : 0.00311
rel_err:0.005861540047188968
Epoch 463 Reg : 0.05888 Train loss : 0.00316
rel_err:0.0058020198577205286
Epoch 464 Reg : 0.05886 Train loss : 0.00317
rel_err:0.006014268911265508
Epoch 465 Reg : 0.05879 Train loss : 0.00316
rel_err:0.005840166296778816
Epoch 466 Reg : 0.05875 Train loss : 0.00309
rel_err:0.00602540944279621
Epoch 467 Reg : 0.05878 Train loss : 0.00318
rel_err:0.005800210889560269
Epoch 468 Reg : 0.05860 Train loss : 0.00304
rel_err:0.0059671373424188216
Epoch 469 Reg : 0.05861 Train loss : 0.00305
rel_err:0.006009668832180214
Epoch 470 Reg : 0.05867 Train loss : 0.00316
rel_err:0.006075145255054863
Epoch 471 Reg : 0.05879 Train loss : 0.00320
rel_err:0.005855669794277298
Epoch 472 Reg : 0.05875 Train loss : 0.00316
rel_err:0.005815002610557876
Epoch 473 Reg : 0.05883 Train loss : 0.00319
rel_err:0.0057999804375166
Epoch 474 Reg : 0.05859 Train loss : 0.00308
rel_err:0.005824764830975561
Epoch 475 Reg : 0.05853 Train loss : 0.00305
rel_err:0.005728932675475528
Epoch 476 Reg : 0.05851 Train loss : 0.00304
rel_err:0.006049909243794462
Epoch 477 Reg : 0.05833 Train loss : 0.00299
rel_err:0.005702523508917123
Epoch 478 Reg : 0.05843 Train loss : 0.00300
rel_err:0.005926669727331264
Epoch 479 Reg : 0.05859 Train loss : 0.00309
rel_err:0.005951073842837259
Epoch 480 Reg : 0.05843 Train loss : 0.00303
rel_err:0.006172725611929174
Epoch 481 Reg : 0.05841 Train loss : 0.00305
rel_err:0.0057943410277128985
Epoch 482 Reg : 0.05835 Train loss : 0.00297
rel_err:0.0057681694218043875
Epoch 483 Reg : 0.05835 Train loss : 0.00295
rel_err:0.005756761227214246
Epoch 484 Reg : 0.05830 Train loss : 0.00300
rel_err:0.005707230148088751
Epoch 485 Reg : 0.05834 Train loss : 0.00301
rel_err:0.0057735859423362545
Epoch 486 Reg : 0.05842 Train loss : 0.00306
rel_err:0.005908994628899159
Epoch 487 Reg : 0.05823 Train loss : 0.00295
rel_err:0.00572415794207294
Epoch 488 Reg : 0.05823 Train loss : 0.00295
rel_err:0.005724068251984909
Epoch 489 Reg : 0.05822 Train loss : 0.00294
rel_err:0.005902427128556351
Epoch 490 Reg : 0.05829 Train loss : 0.00296
rel_err:0.005749184796003146
Epoch 491 Reg : 0.05818 Train loss : 0.00294
rel_err:0.005740435218427808
Epoch 492 Reg : 0.05810 Train loss : 0.00294
rel_err:0.005757166734380294
Epoch 493 Reg : 0.05813 Train loss : 0.00294
rel_err:0.005954227296183286
Epoch 494 Reg : 0.05821 Train loss : 0.00300
rel_err:0.005665377045597952
Epoch 495 Reg : 0.05814 Train loss : 0.00299
rel_err:0.005744559837380476
Epoch 496 Reg : 0.05807 Train loss : 0.00291
rel_err:0.005679850532716947
Epoch 497 Reg : 0.05823 Train loss : 0.00301
rel_err:0.0058559157802444166
Epoch 498 Reg : 0.05812 Train loss : 0.00295
rel_err:0.005707793554128999
Epoch 499 Reg : 0.05797 Train loss : 0.00291
rel_err:0.00567440442168881
save model