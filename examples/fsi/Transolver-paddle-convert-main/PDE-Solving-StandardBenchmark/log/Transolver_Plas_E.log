W1030 13:26:01.756693 1222684 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 12.2, Runtime API Version: 12.0
W1030 13:26:01.757216 1222684 gpu_resources.cc:164] device: 0, cuDNN Version: 9.5.
(987, 101) (987, 101, 31, 4, 20)
(900, 3131, 1) (900, 3131, 4, 20)
Dataloading is over.
Dataloading is over.
Namespace(lr=0.001, epochs=500, weight_decay=1e-05, model='Transolver_Structured_Mesh_2D', n_hidden=64, n_layers=3, n_heads=4, batch_size=8, gpu=0, max_grad_norm=None, downsamplex=1, downsampley=1, mlp_ratio=1, dropout=0.0, unified_pos=0, ref=8, slice_num=32, eval=1, save_name='plas_Transolver', data_path='data/fno/plas_N987_T20.mat')
Model(
  (preprocess): MLP(
    (linear_pre): Sequential(
      (0): Linear(in_features=3, out_features=128, dtype=None)
      (1): GELU(approximate=False)
    )
    (linear_post): Linear(in_features=128, out_features=64, dtype=None)
    (linears): LayerList()
  )
  (time_fc): Sequential(
    (0): Linear(in_features=64, out_features=64, dtype=None)
    (1): Silu()
    (2): Linear(in_features=64, out_features=64, dtype=None)
  )
  (blocks): LayerList(
    (0): Transolver_block(
      (ln_1): LayerNorm(normalized_shape=[64], epsilon=1e-05)
      (Attn): Physics_Attention_Structured_Mesh_2D(
        (softmax): Softmax(axis=-1)
        (dropout): Dropout(p=0.0, axis=None, mode=upscale_in_train)
        (in_project_x): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (in_project_fx): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (in_project_slice): Linear(in_features=16, out_features=32, dtype=None)
        (to_q): Linear(in_features=16, out_features=16, dtype=None)
        (to_k): Linear(in_features=16, out_features=16, dtype=None)
        (to_v): Linear(in_features=16, out_features=16, dtype=None)
        (to_out): Sequential(
          (0): Linear(in_features=64, out_features=64, dtype=None)
          (1): Dropout(p=0.0, axis=None, mode=upscale_in_train)
        )
      )
      (ln_2): LayerNorm(normalized_shape=[64], epsilon=1e-05)
      (mlp): MLP(
        (linear_pre): Sequential(
          (0): Linear(in_features=64, out_features=64, dtype=None)
          (1): GELU(approximate=False)
        )
        (linear_post): Linear(in_features=64, out_features=64, dtype=None)
        (linears): LayerList()
      )
    )
    (1): Transolver_block(
      (ln_1): LayerNorm(normalized_shape=[64], epsilon=1e-05)
      (Attn): Physics_Attention_Structured_Mesh_2D(
        (softmax): Softmax(axis=-1)
        (dropout): Dropout(p=0.0, axis=None, mode=upscale_in_train)
        (in_project_x): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (in_project_fx): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (in_project_slice): Linear(in_features=16, out_features=32, dtype=None)
        (to_q): Linear(in_features=16, out_features=16, dtype=None)
        (to_k): Linear(in_features=16, out_features=16, dtype=None)
        (to_v): Linear(in_features=16, out_features=16, dtype=None)
        (to_out): Sequential(
          (0): Linear(in_features=64, out_features=64, dtype=None)
          (1): Dropout(p=0.0, axis=None, mode=upscale_in_train)
        )
      )
      (ln_2): LayerNorm(normalized_shape=[64], epsilon=1e-05)
      (mlp): MLP(
        (linear_pre): Sequential(
          (0): Linear(in_features=64, out_features=64, dtype=None)
          (1): GELU(approximate=False)
        )
        (linear_post): Linear(in_features=64, out_features=64, dtype=None)
        (linears): LayerList()
      )
    )
    (2): Transolver_block(
      (ln_1): LayerNorm(normalized_shape=[64], epsilon=1e-05)
      (Attn): Physics_Attention_Structured_Mesh_2D(
        (softmax): Softmax(axis=-1)
        (dropout): Dropout(p=0.0, axis=None, mode=upscale_in_train)
        (in_project_x): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (in_project_fx): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (in_project_slice): Linear(in_features=16, out_features=32, dtype=None)
        (to_q): Linear(in_features=16, out_features=16, dtype=None)
        (to_k): Linear(in_features=16, out_features=16, dtype=None)
        (to_v): Linear(in_features=16, out_features=16, dtype=None)
        (to_out): Sequential(
          (0): Linear(in_features=64, out_features=64, dtype=None)
          (1): Dropout(p=0.0, axis=None, mode=upscale_in_train)
        )
      )
      (ln_2): LayerNorm(normalized_shape=[64], epsilon=1e-05)
      (mlp): MLP(
        (linear_pre): Sequential(
          (0): Linear(in_features=64, out_features=64, dtype=None)
          (1): GELU(approximate=False)
        )
        (linear_post): Linear(in_features=64, out_features=64, dtype=None)
        (linears): LayerList()
      )
      (ln_3): LayerNorm(normalized_shape=[64], epsilon=1e-05)
      (mlp2): Linear(in_features=64, out_features=4, dtype=None)
    )
  )
)
Total Trainable Params: 281264
1
2
3
4
5
6
7
8
9
test_step_loss:0.00300 , test_full_loss:0.00332
